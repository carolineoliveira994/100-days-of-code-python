{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPzORNMMmTkpaaVo3lws/Cd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carolineoliveira994/100-days-of-code-python/blob/main/TCC5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate\n",
        "!pip install python-dotenv\n",
        "!pip install spacy textblob\n",
        "!python -m textblob.download_corpora\n",
        "!python -m spacy download pt_core_news_sm  # Modelo em português\n",
        "!pip install unidecode\n",
        "\n",
        "!pip install unidecode nltk spacy\n",
        "!python -m spacy download pt_core_news_sm\n"
      ],
      "metadata": {
        "id": "iIRcujxg6Ttu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import evaluate\n",
        "from dotenv import load_dotenv\n",
        "import spacy\n",
        "import re\n",
        "import unidecode\n",
        "from textblob import TextBlob\n",
        "from nltk.stem import SnowballStemmer\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "import torch\n",
        "from google.colab import files\n",
        "from google.colab import auth\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"Diretório atual:\", os.getcwd())"
      ],
      "metadata": {
        "id": "jJUnZI496N5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WvkMFiP3vAsA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Coleta de dados usando a API da Bluesky\n",
        "\n",
        "\n",
        "**Objetivo**: Obter dados relevantes de postagens, comentários e interações na rede social Bluesky, focando em sentimentos relacionados às eleições de 2024.\n",
        "\n",
        "**Fontes de Dados**: Bluesky.\n",
        "\n",
        "**Técnicas de Coleta:** API do ATProtocol para interagir com os servidores Bluesky.\n",
        "\n",
        "**Autenticação**: Realizar a autenticação necessária para acessar a API, salvar credenciais no arquito .env.\n",
        "\n",
        "**Requisições HTTP:** Endpoints específicos da API que permitem obter postagens, comentários e perfis de usuários.\n",
        "\n",
        "PALAVRAS CHAVES: ELEIÇÕES, CANDITADOS, BOULOS, TABATA, DATENA...\n",
        "\n",
        "**Período de Coleta**: JUNHO.\n"
      ],
      "metadata": {
        "id": "5MlaxnCfs3Ro"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "nrkdzu6FrdZT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Packages:"
      ],
      "metadata": {
        "id": "sWiE_VsXvJp1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XrTiJrTIbOKJ"
      },
      "outputs": [],
      "source": [
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JX8HyCgDvolW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('.env', 'w') as f:\n",
        "    f.write(\"\"\"\n",
        "BLUESKY_APP_USER = 'cocorolini.bsky.social'\n",
        "BLUESKY_APP_PASS='3ovj-gbnh-trwd-k66r'\n",
        "\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "zs6iabB95QHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Busca no BLUESKY com a palavra chave \"ELEIÇÕES\""
      ],
      "metadata": {
        "id": "LJkfVJ5rwFGh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py search POLITICA --sort latest --limit 90\n"
      ],
      "metadata": {
        "id": "1pHULWJI5TTE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cria DataFrame"
      ],
      "metadata": {
        "id": "J3vrlGg-wIEP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = './data/search_results_POLITICA_2024_09_22.csv'\n",
        "df_POLITICA = pd.read_csv(file_path)\n",
        "df_POLITICA"
      ],
      "metadata": {
        "id": "C4-_YysA5VQ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lista DataFrame criados"
      ],
      "metadata": {
        "id": "aJTVuhxAwMsZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe_names = [name for name, obj in globals().items() if isinstance(obj, pd.DataFrame)]\n",
        "print(dataframe_names)"
      ],
      "metadata": {
        "id": "XIwurn5p66NV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Junta os DataFrames\n",
        "\n"
      ],
      "metadata": {
        "id": "XGhfGpuSwRYA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataframes = [\"df_boulos\", \"df_guilhermeboulos\", \"df_tabata\", \"df_tabataamaral\", \"df_novo\", \"df_altino\",\n",
        "             \"df_marçal\", \"df_bebeto\", \"df_datena\", \"df_RicardoNunes\", \"df_RICARDONUNES\", \"df_MDB\",\n",
        "             \"df_GuilhermeBoulos\", \"df_BOULOS\", \"df_PSOL\", \"df_PabloMarçal\", \"df_PRTB\", \"df_TabataAmaral\",\n",
        "             \"df_amaral\", \"df_PSB\", \"df_Datena\", \"df_DATENA\", \"df_PSDB\", \"df_PREFEITO\", \"_74\", \"df_CANDIDATO\",\n",
        "             \"_77\", \"df_ELEITORAL\", \"df_VOTO\", \"df_POLITICA\"]\n",
        "\n",
        "dataframes_to_concat = [globals()[name] for name in dataframes if name in globals()]\n",
        "\n",
        "df_concatenado = pd.concat(dataframes_to_concat, ignore_index=True)\n",
        "print(df_concatenado)"
      ],
      "metadata": {
        "id": "gN6qTCjYHuCH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_W3UT2WGIwie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_concatenado"
      ],
      "metadata": {
        "id": "ukIr_XUFHkMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remover colunas não ultilizadas"
      ],
      "metadata": {
        "id": "N3dnOmzkwfcG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_remove = [\"reply_count\", \"author_display_name\", \"author_handle\", \"indexed_at\", \"cid\", \"uri\", \"created_at\", \"repost_count\", \"like_count\"]\n",
        "df_concatenado = df_concatenado.drop(columns=columns_to_remove)\n",
        "\n",
        "print(\"\\nDepois:\")\n",
        "print(df_concatenado)\n"
      ],
      "metadata": {
        "id": "cKAa0Sv9JgES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "vc6D1jhMJ4EM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Limpeza: Remoção de stop words: Palavras comuns que não adicionam significado (ex: \"a\", \"o\", \"de\").\n",
        "Remoção de pontuação: Pontuação pode interferir na análise.\n",
        "Remoção de números: Se não forem relevantes para a análise de sentimentos.\n",
        "Correção de erros de digitação: Utilizando técnicas de correção ortográfica."
      ],
      "metadata": {
        "id": "-1_kWvYvKgtz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Autenticação hugg****ntirar"
      ],
      "metadata": {
        "id": "AVIYDADkwk10"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "os.environ['HF_TOKEN'] = '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'\n"
      ],
      "metadata": {
        "id": "pZ-eMcvDP2bn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparar o BERT para análise de sentimentos com três rótulos (positivo, negativo e neutro)"
      ],
      "metadata": {
        "id": "imnbIZ1-wunc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased')\n",
        "model = BertForSequenceClassification.from_pretrained('neuralmind/bert-base-portuguese-cased', num_labels=3)\n"
      ],
      "metadata": {
        "id": "n0W6A385NkOC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_concatenado['label'].unique())\n"
      ],
      "metadata": {
        "id": "Fx3-TA7lPRBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fluxo de Pré-processamento com spaCy\n",
        "\n",
        "* Remoção de URLs.\n",
        "* Remoção de menções.\n",
        "* Remoção de hashtags.\n",
        "* Remoção de números.\n",
        "* Remoção de acentos.\n",
        "* Conversão para minúsculas\n",
        "* Lematização e remoção de stop words e pontuação: Usa o spaCy para remover stop words e pontuação e retorna o texto lematizado.\n"
      ],
      "metadata": {
        "id": "1hyGhaLFxfGY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"pt_core_news_sm\")\n",
        "\n",
        "def clean_text(text):\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"  # Retorna uma string vazia se o texto não for string\n",
        "\n",
        "    # Remover URLs\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
        "\n",
        "    # Remover menções (@username)\n",
        "    text = re.sub(r'@\\w+', '', text)\n",
        "\n",
        "    # Remover hashtags (#hashtag)\n",
        "    text = re.sub(r'#\\w+', '', text)\n",
        "\n",
        "    # Remover números\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "\n",
        "    # Remover acentos\n",
        "    text = unidecode.unidecode(text)\n",
        "\n",
        "    # Converter para minúsculas\n",
        "    text = text.lower()\n",
        "\n",
        "    # Processar o texto com spaCy\n",
        "    doc = nlp(text)\n",
        "\n",
        "    # Remover stop words e pontuação\n",
        "    cleaned_text = ' '.join([token.lemma_ for token in doc if not token.is_stop and not token.is_punct])\n",
        "\n",
        "    return cleaned_text\n",
        "\n",
        "texts = df_concatenado['text'].tolist()\n",
        "cleaned_texts = [clean_text(text) for text in texts]\n",
        "\n",
        "df_concatenado['cleaned_text'] = cleaned_texts\n",
        "print(df_concatenado[['text', 'cleaned_text']].head())\n"
      ],
      "metadata": {
        "id": "pi06AHArKjVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "jlK4qJfbQlnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aplicar a função para rotular automaticamente os textos"
      ],
      "metadata": {
        "id": "SwLKDv59yHBh"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Lc7Vb9E3yqgK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definição das listas de palavras-chave (Features)"
      ],
      "metadata": {
        "id": "-pgEL10CyuyY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def label_text(text):\n",
        "    positive_keywords = ['ótimo', 'Amor', 'sucesso', 'vitória', 'esperança', 'sorriso', 'celebrar', 'melhorar', 'perfeito', 'bom', 'maravilhoso', 'adoro', 'excelente', 'Prefeito', 'incrível', 'demais', 'casa comigo', 'delicia', 'Boulos50', 'boulos50', 'proposta', 'conhece', 'feliz', 'positivo', 'agradável', 'conquista', 'forte', 'brilhante', 'valioso', 'benéfico', 'grato', 'aprimorar', 'jovial', 'vibrante', 'cheio de vida', 'vitalidade', 'tranquilo', 'satisfatório', 'ansioso', 'animado', 'compreensivo', 'carinhoso', 'amigável', 'determinado', 'fortalecer', 'aceitar', 'progresso', 'união', 'alegria', 'bravo', 'realizar', 'gentil', 'benigno', 'felicidade', 'delicioso', 'apaixonado', 'otimismo', 'cooperar', 'triumphar', 'brilhante', 'jubilante', 'extraordinário', 'esplêndido', 'efetivo', 'fortalecedor', 'valioso', 'resiliente', 'serenidade', 'pleno', 'visionário', 'original', 'cativante', 'sincero', 'dedicado', 'ousado', 'alegre', 'sereno', 'gracioso', 'próspero', 'compassivo', 'energizante', 'instigante', 'transformador', 'animador', 'caridade', 'generoso', 'estudioso']\n",
        "    negative_keywords = ['manipulacao', 'manipulação' 'ruim', 'horrível', 'pior', 'não recomendo', 'credo', 'vagabundo', 'nojo', 'odiar', 'desapontar', 'quebrar', 'perder', 'ignorar', 'negar', 'fracassar', 'destruir', 'desfavoritar', 'desencorajar', 'fracasso', 'desespero', 'problema', 'dificuldade', 'raiva', 'tristeza', 'crítica', 'frustração', 'desilusão', 'desânimo', 'decepcionante', 'terrível', 'insatisfatório', 'chato', 'aborrecido', 'desagradável', 'desastroso', 'incapaz', 'fraco', 'desapontador', 'chateado', 'injusto', 'mal', 'tenso', 'descontentamento', 'fracassado', 'abandonado', 'desesperado', 'angustiante', 'inadequado', 'infeliz', 'irritante', 'desprezível', 'desfavorável', 'hostil', 'dificultoso', 'insuficiente', 'arrogante', 'desprezível', 'triste', 'crueldade', 'injustiça', 'desgosto', 'aflição', 'desprezo', 'inseguro', 'abominável', 'afrontoso', 'dissonante', 'constrangedor', 'frustrante', 'pessimista', 'insatisfação', 'fúria', 'rejeição', 'desfavor', 'maléfico', 'dano', 'desprezo', 'deprimente', 'perturbador', 'ruína', 'fiasco', 'afronta', 'cárcere', 'desventurado', 'desgrace', 'desolador', 'tóxico', 'trágico', 'desaparecimento', 'caos', 'medo', 'aflição', 'perturbação', 'hostilidade', 'destruição']\n",
        "\n",
        "    if any(word in text for word in positive_keywords):\n",
        "        return 1  # Positivo\n",
        "    elif any(word in text for word in negative_keywords):\n",
        "        return 0  # Negativo\n",
        "    else:\n",
        "        return 2  # Neutro ou indefinido\n",
        "\n",
        "df_concatenado['label'] = df_concatenado['cleaned_text'].apply(label_text)\n",
        "\n",
        "print(df_concatenado[['text', 'cleaned_text', 'label']])\n"
      ],
      "metadata": {
        "id": "WVgrv1MgREMi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_concatenado"
      ],
      "metadata": {
        "id": "Chem4r75Vk3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "train_test_split da biblioteca sklearn é utilizada para dividir os dados em duas partes, uma para treinamento do modelo e outra para avaliação teste\n",
        "\n",
        "mportância da Divisão Estratificada:\n",
        "Como você está lidando com um problema de análise de sentimentos com três rótulos (positivo, negativo, neutro), é importante garantir que o modelo veja uma proporção representativa de cada classe durante o treinamento e também durante a avaliação. Isso é especialmente relevante quando as classes são desbalanceadas, como no seu caso (com muito mais instâncias positivas do que negativas e neutras).\n",
        "\n",
        "Exemplo Prático:\n",
        "Se você tem um total de 2641 instâncias no DataFrame df_concatenado, a divisão estratificada irá garantir algo como:\n",
        "\n",
        "Treinamento: Aproximadamente 2112 instâncias (80% do total), distribuídas de maneira proporcional aos rótulos.\n",
        "Avaliação: Aproximadamente 529 instâncias (20% do total), também com a mesma distribuição proporcional."
      ],
      "metadata": {
        "id": "LMwOkQXxzsb1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, eval_df = train_test_split(df_concatenado, test_size=0.2, random_state=42, stratify=df_concatenado['label'])\n",
        "\n",
        "print(\"Dados de Treinamento:\")\n",
        "print(train_df.head())\n",
        "print(\"\\nDados de Avaliação:\")\n",
        "print(eval_df.head())\n"
      ],
      "metadata": {
        "id": "JtrshX7zaZ9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_concatenado['label'].value_counts())\n"
      ],
      "metadata": {
        "id": "6iRTqTN7a2yV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_concatenado['label'].value_counts())\n"
      ],
      "metadata": {
        "id": "e29sab76gT3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FXCasPiM0u5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenizar os textos usando o BERT em português\n",
        "\n",
        "**input_ids**: IDs numéricos correspondentes aos tokens do texto.\n",
        "\n",
        "**attention_mask**: Máscara de atenção que indica quais tokens são reais e quais são padding (zeros)."
      ],
      "metadata": {
        "id": "cudGJiMt01ZH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased')\n",
        "\n",
        "def tokenize_function(texts):\n",
        "    return tokenizer(texts, padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")\n",
        "\n",
        "train_encodings = tokenize_function(train_df['cleaned_text'].tolist())\n",
        "eval_encodings = tokenize_function(eval_df['cleaned_text'].tolist())\n"
      ],
      "metadata": {
        "id": "a4TCF2JpgX_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hnm-I5t-p42a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Definir o SentimentDataset e os loaders de dados de treinamento e avaliação.\n",
        "\n",
        "**SentimentDataset**: organiza os dados de entrada (codificações e rótulos) para que possam ser usados pelo modelo.\n",
        "\n",
        "**DataLoader**: facilita o carregamento dos dados em lotes para alimentar o modelo durante o treinamento e a avaliação."
      ],
      "metadata": {
        "id": "Q6Oa8hOR1W9L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "class SentimentDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = SentimentDataset(train_encodings, train_df['label'].tolist())\n",
        "eval_dataset = SentimentDataset(eval_encodings, eval_df['label'].tolist())\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "eval_loader = DataLoader(eval_dataset, batch_size=8, shuffle=False)\n"
      ],
      "metadata": {
        "id": "seVXyhnegaz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configuração do ambiente de treinamento, permitindo o controle sobre o processo de otimização, salvamento de modelos e avaliação, garantindo o monitoraramento do desempenho ao longo do tempo."
      ],
      "metadata": {
        "id": "VAdnyxPSTPUT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    learning_rate=3e-5,\n",
        "    evaluation_strategy='epoch',\n",
        "    logging_steps=10,\n",
        "    save_steps=500,\n",
        "    load_best_model_at_end=True,\n",
        "    weight_decay=0.01,\n",
        "    metric_for_best_model='accuracy',\n",
        "    greater_is_better=True,\n",
        "    logging_dir='./logs',\n",
        ")\n"
      ],
      "metadata": {
        "id": "agCpg-9hceJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Criar o Trainer\n",
        "\n",
        "configura e inicia o treinamento do modelo BERT para classificação de sentimentos usando a biblioteca transformers\n"
      ],
      "metadata": {
        "id": "daTW-BwKpw_Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer, BertForSequenceClassification\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained('neuralmind/bert-base-portuguese-cased', num_labels=3) #modelo BERT pré-treinado específico para a língua portuguesa\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset, #conjunto de dados de treinamento a ser utilizado\n",
        "    eval_dataset=eval_dataset     #conjunto de dados de avaliação para monitorar o desempenho do modelo durante o treinamento\n",
        ")\n"
      ],
      "metadata": {
        "id": "Fu-qJlR1goZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()\n"
      ],
      "metadata": {
        "id": "ovGO9iXngqEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# métricas de desempenho do modelo no conjunto de dados de **avaliação**"
      ],
      "metadata": {
        "id": "rPZn8AY-5eMQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate()\n"
      ],
      "metadata": {
        "id": "Rh7hxw8VgrUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained('./model')\n",
        "tokenizer.save_pretrained('./model')\n"
      ],
      "metadata": {
        "id": "l3Z3WUbJgtSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "AVALIAÇÃO"
      ],
      "metadata": {
        "id": "nkyoFe5hkZ_j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses = []  # Adicione valores de perda do treinamento\n",
        "eval_losses = []   # Adicione valores de perda da validação\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(train_losses, label='Training Loss', color='blue')\n",
        "plt.plot(eval_losses, label='Validation Loss', color='orange')\n",
        "plt.title('Loss over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "cr7ycbcOk6Xc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}