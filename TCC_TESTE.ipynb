{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNEZw9k6xC3gK0CBOOygAH5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carolineoliveira994/100-days-of-code-python/blob/main/TCC_TESTE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate\n",
        "!pip install python-dotenv\n",
        "!pip install spacy textblob\n",
        "!python -m textblob.download_corpora\n",
        "!python -m spacy download pt_core_news_sm  # Modelo em português\n",
        "!pip install unidecode\n",
        "\n",
        "!pip install unidecode nltk spacy\n",
        "!python -m spacy download pt_core_news_sm\n"
      ],
      "metadata": {
        "id": "iIRcujxg6Ttu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import evaluate\n",
        "from dotenv import load_dotenv\n",
        "import spacy\n",
        "import re\n",
        "import unidecode\n",
        "from textblob import TextBlob\n",
        "from nltk.stem import SnowballStemmer\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "import torch\n",
        "from google.colab import files\n",
        "from google.colab import auth\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"Diretório atual:\", os.getcwd())"
      ],
      "metadata": {
        "id": "jJUnZI496N5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WvkMFiP3vAsA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Coleta de dados usando a API da Bluesky\n",
        "\n",
        "\n",
        "**Objetivo**: Obter dados relevantes de postagens, comentários e interações na rede social Bluesky, focando em sentimentos relacionados às eleições de 2024.\n",
        "\n",
        "**Fontes de Dados**: Bluesky.\n",
        "\n",
        "**Técnicas de Coleta:** API do ATProtocol para interagir com os servidores Bluesky.\n",
        "\n",
        "**Autenticação**: Realizar a autenticação necessária para acessar a API, salvar credenciais no arquito .env.\n",
        "\n",
        "**Requisições HTTP:** Endpoints específicos da API que permitem obter postagens, comentários e perfis de usuários.\n",
        "\n",
        "PALAVRAS CHAVES: ELEIÇÕES, CANDITADOS, BOULOS, TABATA, DATENA...\n",
        "\n",
        "**Período de Coleta**: JUNHO.\n"
      ],
      "metadata": {
        "id": "5MlaxnCfs3Ro"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "nrkdzu6FrdZT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Packages:"
      ],
      "metadata": {
        "id": "sWiE_VsXvJp1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XrTiJrTIbOKJ"
      },
      "outputs": [],
      "source": [
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JX8HyCgDvolW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('.env', 'w') as f:\n",
        "    f.write(\"\"\"\n",
        "BLUESKY_APP_USER = 'cocorolini.bsky.social'\n",
        "BLUESKY_APP_PASS='3ovj-gbnh-trwd-k66r'\n",
        "\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "zs6iabB95QHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Busca no BLUESKY com a palavra chave \"ELEIÇÕES\""
      ],
      "metadata": {
        "id": "LJkfVJ5rwFGh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py search PREFEITO --sort latest --limit 90\n"
      ],
      "metadata": {
        "id": "1pHULWJI5TTE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cria DataFrame"
      ],
      "metadata": {
        "id": "J3vrlGg-wIEP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = './data/search_results_PREFEITO_2024_09_24.csv'\n",
        "df_PREFEITO = pd.read_csv(file_path)\n",
        "df_PREFEITO"
      ],
      "metadata": {
        "id": "C4-_YysA5VQ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lista DataFrame criados"
      ],
      "metadata": {
        "id": "aJTVuhxAwMsZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe_names = [name for name, obj in globals().items() if isinstance(obj, pd.DataFrame)]\n",
        "print(dataframe_names)"
      ],
      "metadata": {
        "id": "XIwurn5p66NV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Junta os DataFrames\n",
        "\n"
      ],
      "metadata": {
        "id": "XGhfGpuSwRYA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataframes = [\"df_boulos\", \"df_guilhermeboulos\", \"df_tabata\", \"df_tabataamaral\", \"df_novo\", \"df_altino\",\n",
        "             \"df_marçal\", \"df_bebeto\", \"df_datena\", \"df_RicardoNunes\", \"df_RICARDONUNES\", \"df_MDB\",\n",
        "             \"df_GuilhermeBoulos\", \"df_BOULOS\", \"df_PSOL\", \"df_PabloMarçal\", \"df_PRTB\", \"df_TabataAmaral\",\n",
        "             \"df_amaral\", \"df_PSB\", \"df_Datena\", \"df_DATENA\", \"df_PSDB\", \"df_PREFEITO\", \"_74\", \"df_CANDIDATO\",\n",
        "             \"_77\", \"df_ELEITORAL\", \"df_VOTO\", \"df_POLITICA\"]\n",
        "\n",
        "dataframes_to_concat = [globals()[name] for name in dataframes if name in globals()]\n",
        "\n",
        "df_concatenado = pd.concat(dataframes_to_concat, ignore_index=True)\n",
        "print(df_concatenado)"
      ],
      "metadata": {
        "id": "gN6qTCjYHuCH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_W3UT2WGIwie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_PREFEITO"
      ],
      "metadata": {
        "id": "ukIr_XUFHkMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remover colunas não ultilizadas"
      ],
      "metadata": {
        "id": "N3dnOmzkwfcG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_remove = [\"reply_count\", \"author_display_name\", \"author_handle\", \"indexed_at\", \"cid\", \"uri\", \"created_at\", \"repost_count\", \"like_count\"]\n",
        "df_PREFEITO = df_PREFEITO.drop(columns=columns_to_remove)\n",
        "\n",
        "print(\"\\nDepois:\")\n",
        "print(df_PREFEITO)\n"
      ],
      "metadata": {
        "id": "cKAa0Sv9JgES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "vc6D1jhMJ4EM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Limpeza: Remoção de stop words: Palavras comuns que não adicionam significado (ex: \"a\", \"o\", \"de\").\n",
        "Remoção de pontuação: Pontuação pode interferir na análise.\n",
        "Remoção de números: Se não forem relevantes para a análise de sentimentos.\n",
        "Correção de erros de digitação: Utilizando técnicas de correção ortográfica."
      ],
      "metadata": {
        "id": "-1_kWvYvKgtz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Autenticação hugg****ntirar"
      ],
      "metadata": {
        "id": "AVIYDADkwk10"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "os.environ['HF_TOKEN'] = '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'\n"
      ],
      "metadata": {
        "id": "pZ-eMcvDP2bn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparar o BERT para análise de sentimentos com três rótulos (positivo, negativo e neutro)"
      ],
      "metadata": {
        "id": "imnbIZ1-wunc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased')\n",
        "model = BertForSequenceClassification.from_pretrained('neuralmind/bert-base-portuguese-cased', num_labels=3)\n"
      ],
      "metadata": {
        "id": "n0W6A385NkOC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_PREFEITO['label'].unique())\n"
      ],
      "metadata": {
        "id": "Fx3-TA7lPRBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fluxo de Pré-processamento com spaCy\n",
        "\n",
        "* Remoção de URLs.\n",
        "* Remoção de menções.\n",
        "* Remoção de hashtags.\n",
        "* Remoção de números.\n",
        "* Remoção de acentos.\n",
        "* Conversão para minúsculas\n",
        "* Lematização e remoção de stop words e pontuação: Usa o spaCy para remover stop words e pontuação e retorna o texto lematizado.\n"
      ],
      "metadata": {
        "id": "1hyGhaLFxfGY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"pt_core_news_sm\")\n",
        "\n",
        "def clean_text(text):\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"  # Retorna uma string vazia se o texto não for string\n",
        "\n",
        "    # Remover URLs\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
        "\n",
        "    # Remover menções (@username)\n",
        "    text = re.sub(r'@\\w+', '', text)\n",
        "\n",
        "    # Remover hashtags (#hashtag)\n",
        "    text = re.sub(r'#\\w+', '', text)\n",
        "\n",
        "    # Remover números\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "\n",
        "    # Remover acentos\n",
        "    text = unidecode.unidecode(text)\n",
        "\n",
        "    # Converter para minúsculas\n",
        "    text = text.lower()\n",
        "\n",
        "    # Processar o texto com spaCy\n",
        "    doc = nlp(text)\n",
        "\n",
        "    # Remover stop words e pontuação\n",
        "    cleaned_text = ' '.join([token.lemma_ for token in doc if not token.is_stop and not token.is_punct])\n",
        "\n",
        "    return cleaned_text\n",
        "\n",
        "texts = df_PREFEITO['text'].tolist()\n",
        "cleaned_texts = [clean_text(text) for text in texts]\n",
        "\n",
        "df_PREFEITO['cleaned_text'] = cleaned_texts\n",
        "print(df_PREFEITO[['text', 'cleaned_text']].head())\n"
      ],
      "metadata": {
        "id": "pi06AHArKjVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_PREFEITO.shape"
      ],
      "metadata": {
        "id": "jlK4qJfbQlnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aplicar a função para rotular automaticamente os textos"
      ],
      "metadata": {
        "id": "SwLKDv59yHBh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Distribuição de Comprimento de Textos"
      ],
      "metadata": {
        "id": "jLrychjJID1b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definição das listas de palavras-chave (Features)"
      ],
      "metadata": {
        "id": "-pgEL10CyuyY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from transformers import pipeline\n",
        "\n",
        "data = df_PREFEITO['cleaned_text']\n",
        "#Criar DataFrame\n",
        "df_PREFEITO = pd.DataFrame(data)\n",
        "\n",
        "# Carregar o pipeline de análise de sentimentos com modelo pré-treinado\n",
        "sentiment_pipeline = pipeline('sentiment-analysis', model='nlptown/bert-base-multilingual-uncased-sentiment')\n",
        "\n",
        "# Classificar sentimentos\n",
        "df_PREFEITO['sentiment'] = df_PREFEITO['cleaned_text'].apply(lambda x: sentiment_pipeline(x)[0]['label'])\n",
        "\n",
        "# Visualizar o DataFrame com os rótulos\n",
        "print(df_PREFEITO)\n"
      ],
      "metadata": {
        "id": "OGOKSKJhHuRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from transformers import pipeline\n",
        "\n",
        "# Carregar a coluna 'cleaned_text' do DataFrame\n",
        "data = df_PREFEITO['cleaned_text']\n",
        "df_PREFEITO = pd.DataFrame(data)\n",
        "\n",
        "# Carregar o pipeline de análise de sentimentos com modelo pré-treinado\n",
        "sentiment_pipeline = pipeline('sentiment-analysis', model='nlptown/bert-base-multilingual-uncased-sentiment')\n",
        "\n",
        "# Mapeamento dos rótulos para categorias\n",
        "label_mapping = {\n",
        "    '1 star': 'negativo',\n",
        "    '2 stars': 'negativo',\n",
        "    '3 stars': 'neutro',\n",
        "    '4 stars': 'positivo',\n",
        "    '5 stars': 'positivo'\n",
        "}\n",
        "\n",
        "# Classificar sentimentos e mapear para os rótulos desejados\n",
        "df_PREFEITO['sentiment'] = df_PREFEITO['cleaned_text'].apply(lambda x: label_mapping[sentiment_pipeline(x)[0]['label']])\n",
        "\n",
        "# Visualizar o DataFrame com os rótulos\n",
        "print(df_PREFEITO)\n"
      ],
      "metadata": {
        "id": "GBemsIl6Hh-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_PREFEITO"
      ],
      "metadata": {
        "id": "8NBvkvPtL-5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_concatenado"
      ],
      "metadata": {
        "id": "Chem4r75Vk3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "train_test_split da biblioteca sklearn é utilizada para dividir os dados em duas partes, uma para treinamento do modelo e outra para avaliação teste\n",
        "\n",
        "mportância da Divisão Estratificada:\n",
        "Como você está lidando com um problema de análise de sentimentos com três rótulos (positivo, negativo, neutro), é importante garantir que o modelo veja uma proporção representativa de cada classe durante o treinamento e também durante a avaliação. Isso é especialmente relevante quando as classes são desbalanceadas, como no seu caso (com muito mais instâncias positivas do que negativas e neutras).\n",
        "\n",
        "Exemplo Prático:\n",
        "Se você tem um total de 2641 instâncias no DataFrame df_concatenado, a divisão estratificada irá garantir algo como:\n",
        "\n",
        "Treinamento: Aproximadamente 2112 instâncias (80% do total), distribuídas de maneira proporcional aos rótulos.\n",
        "Avaliação: Aproximadamente 529 instâncias (20% do total), também com a mesma distribuição proporcional."
      ],
      "metadata": {
        "id": "LMwOkQXxzsb1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, eval_df = train_test_split(df_PREFEITO, test_size=0.2, random_state=42, stratify=df_PREFEITO['sentiment'])\n",
        "\n",
        "print(\"Dados de Treinamento:\")\n",
        "print(train_df.head())\n",
        "print(\"\\nDados de Avaliação:\")\n",
        "print(eval_df.head())\n"
      ],
      "metadata": {
        "id": "JtrshX7zaZ9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_PREFEITO['sentiment'].value_counts())\n"
      ],
      "metadata": {
        "id": "6iRTqTN7a2yV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim\n",
        "!pip install nltk\n",
        "!pip install pandas\n"
      ],
      "metadata": {
        "id": "FXCasPiM0u5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenizar os textos usando o BERT em português\n",
        "\n",
        "**input_ids**: IDs numéricos correspondentes aos tokens do texto.\n",
        "\n",
        "**attention_mask**: Máscara de atenção que indica quais tokens são reais e quais são padding (zeros)."
      ],
      "metadata": {
        "id": "cudGJiMt01ZH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Carregar o tokenizer do modelo pré-treinado em português\n",
        "tokenizer = BertTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased')\n",
        "\n",
        "# Função para tokenizar os textos\n",
        "def tokenize_function(texts):\n",
        "    return tokenizer(texts, padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")\n",
        "\n",
        "# Tokenizar os dados de treinamento e de avaliação\n",
        "train_encodings = tokenize_function(train_df['cleaned_text'].tolist())\n",
        "eval_encodings = tokenize_function(eval_df['cleaned_text'].tolist())\n",
        "\n",
        "# Exibir a estrutura dos encodings gerados\n",
        "print(train_encodings.keys())  # Mostra as chaves, como 'input_ids', 'attention_mask'\n",
        "print(eval_encodings.keys())\n"
      ],
      "metadata": {
        "id": "a4TCF2JpgX_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "teste"
      ],
      "metadata": {
        "id": "D8JkT0jVViyU"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ftYfksDSncLg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Definir o SentimentDataset e os loaders de dados de treinamento e avaliação.\n",
        "\n",
        "**SentimentDataset**: organiza os dados de entrada (codificações e rótulos) para que possam ser usados pelo modelo.\n",
        "\n",
        "**DataLoader**: facilita o carregamento dos dados em lotes para alimentar o modelo durante o treinamento e a avaliação."
      ],
      "metadata": {
        "id": "Q6Oa8hOR1W9L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class SentimentAnalysisDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Usar .clone().detach() para evitar o aviso\n",
        "        item = {key: val[idx].clone().detach() for key, val in self.encodings.items()}\n",
        "\n",
        "        # Garantir que os rótulos estejam no formato correto\n",
        "        item['sentiment'] = torch.tensor(int(self.labels[idx]), dtype=torch.long)\n",
        "\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "# Mapear os rótulos para números usando o mapeamento\n",
        "label_mapping = {\"positivo\": 2, \"neutro\": 1, \"negativo\": 0}\n",
        "train_labels = [label_mapping[label] for label in train_df['sentiment']]\n",
        "eval_labels = [label_mapping[label] for label in eval_df['sentiment']]\n",
        "\n",
        "# Criar os datasets para treinamento e avaliação\n",
        "train_dataset = SentimentAnalysisDataset(train_encodings, train_labels)\n",
        "eval_dataset = SentimentAnalysisDataset(eval_encodings, eval_labels)\n"
      ],
      "metadata": {
        "id": "seVXyhnegaz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForSequenceClassification\n",
        "\n",
        "# Carregar o modelo BERT para classificação com 3 rótulos (positivo, neutro, negativo)\n",
        "model = BertForSequenceClassification.from_pretrained('neuralmind/bert-base-portuguese-cased', num_labels=3)\n"
      ],
      "metadata": {
        "id": "L2no0EGWIYhL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Definir o otimizador (usando Adam, mas pode ser alterado para outro otimizador)\n",
        "optimizer = optim.Adam(model.parameters(), lr=2e-5)  # lr = taxa de aprendizado (learning rate)\n",
        "\n",
        "# Definir a função de perda (loss function)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()  # Como você tem rótulos categóricos (positivo, neutro, negativo), CrossEntropyLoss é adequada\n"
      ],
      "metadata": {
        "id": "0bDkXMVRIRlX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Defina o número de épocas\n",
        "num_epochs = 5  # Defina o número de épocas que você deseja treinar\n",
        "\n",
        "# Inicialize listas para armazenar as perdas\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "# Crie DataLoader para os datasets de treinamento e validação\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)  # Ajuste o tamanho do lote conforme necessário\n",
        "eval_loader = DataLoader(eval_dataset, batch_size=16)  # Ajuste o tamanho do lote conforme necessário\n",
        "\n",
        "# Exemplo de loop de treinamento\n",
        "for epoch in range(num_epochs):\n",
        "    # Treinamento\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    for batch in train_loader:\n",
        "        optimizer.zero_grad()  # Zera os gradientes\n",
        "        outputs = model(batch['input_ids'], attention_mask=batch['attention_mask'])\n",
        "        loss = loss_fn(outputs.logits, batch['sentiment'])\n",
        "        loss.backward()  # Calcula os gradientes\n",
        "        optimizer.step()  # Atualiza os pesos\n",
        "        train_loss += loss.item()  # Soma a perda\n",
        "\n",
        "    train_losses.append(train_loss / len(train_loader))  # Média da perda de treinamento\n",
        "\n",
        "    # Avaliação\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():  # Desativa o cálculo de gradientes\n",
        "        for batch in eval_loader:\n",
        "            outputs = model(batch['input_ids'], attention_mask=batch['attention_mask'])\n",
        "            loss = loss_fn(outputs.logits, batch['sentiment'])\n",
        "            val_loss += loss.item()  # Soma a perda de validação\n",
        "\n",
        "    val_losses.append(val_loss / len(eval_loader))  # Média da perda de validação\n",
        "\n",
        "# Após o treinamento, você pode plotar os resultados\n",
        "# Gráfico de Precisão e Recall\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_precisions, label='Precisão de Treinamento')\n",
        "plt.plot(val_precisions, label='Precisão de Validação')\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Precisão')\n",
        "plt.legend()\n",
        "plt.title('Precisão ao Longo das Épocas')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(train_recalls, label='Recall de Treinamento')\n",
        "plt.plot(val_recalls, label='Recall de Validação')\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Recall')\n",
        "plt.legend()\n",
        "plt.title('Recall ao Longo das Épocas')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "INc7an-eJFql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "import torch\n",
        "\n",
        "train_precisions = []\n",
        "train_recalls = []\n",
        "val_precisions = []\n",
        "val_recalls = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # Treinamento\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    y_true_train = []\n",
        "    y_pred_train = []\n",
        "\n",
        "# Sem cálculo de gradientes durante a avaliação\n",
        "with torch.no_grad():\n",
        "    for batch in eval_loader:\n",
        "        outputs = model(batch['input_ids'], attention_mask=batch['attention_mask'])\n",
        "\n",
        "        # Obter as predições\n",
        "        logits = outputs.logits\n",
        "        preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
        "\n",
        "        # Adicionar as predições e rótulos verdadeiros\n",
        "        predictions.extend(preds)\n",
        "        true_labels.extend(batch['labels'].cpu().numpy())\n",
        "\n",
        "# Calcular accuracy\n",
        "accuracy = accuracy_score(true_labels, predictions)\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "\n",
        "# Calcular precision, recall e f1-score\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predictions, average='weighted')\n",
        "\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n"
      ],
      "metadata": {
        "id": "17VMtcTQnlDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tTsS8B7enmes"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score\n",
        "\n",
        "# Inicialize listas para armazenar a precisão e o recall\n",
        "train_precisions = []\n",
        "train_recalls = []\n",
        "val_precisions = []\n",
        "val_recalls = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # Treinamento\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    y_true_train = []\n",
        "    y_pred_train = []\n",
        "\n",
        "    for batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(batch['input_ids'], attention_mask=batch['attention_mask'])\n",
        "        loss = loss_fn(outputs.logits, batch['sentiment'])\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        # Armazena os rótulos verdadeiros e previstos\n",
        "        y_true_train.extend(batch['labels'].tolist())\n",
        "        y_pred_train.extend(outputs.logits.argmax(dim=1).tolist())\n",
        "\n",
        "    train_precisions.append(precision_score(y_true_train, y_pred_train, average='weighted'))\n",
        "    train_recalls.append(recall_score(y_true_train, y_pred_train, average='weighted'))\n",
        "\n",
        "    # Avaliação\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    y_true_val = []\n",
        "    y_pred_val = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in eval_loader:\n",
        "            outputs = model(batch['input_ids'], attention_mask=batch['attention_mask'])\n",
        "            loss = loss_fn(outputs.logits, batch['sentiment'])\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            # Armazena os rótulos verdadeiros e previstos\n",
        "            y_true_val.extend(batch['sentiment'].tolist())\n",
        "            y_pred_val.extend(outputs.logits.argmax(dim=1).tolist())\n",
        "\n",
        "    val_precisions.append(precision_score(y_true_val, y_pred_val, average='weighted'))\n",
        "    val_recalls.append(recall_score(y_true_val, y_pred_val, average='weighted'))\n",
        "\n",
        "# Gráfico de Precisão e Recall\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_precisions, label='Precisão de Treinamento')\n",
        "plt.plot(val_precisions, label='Precisão de Validação')\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Precisão')\n",
        "plt.legend()\n",
        "plt.title('Precisão ao Longo das Épocas')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(train_recalls, label='Recall de Treinamento')\n",
        "plt.plot(val_recalls, label='Recall de Validação')\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Recall')\n",
        "plt.legend()\n",
        "plt.title('Recall ao Longo das Épocas')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "B2c8oyUhMAGq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Salvar o modelo treinado\n",
        "model.save_pretrained('caminho_para_salvar_o_modelo')\n",
        "tokenizer.save_pretrained('caminho_para_salvar_o_tokenizer')\n"
      ],
      "metadata": {
        "id": "cGV6CPvwJF_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configuração do ambiente de treinamento, permitindo o controle sobre o processo de otimização, salvamento de modelos e avaliação, garantindo o monitoraramento do desempenho ao longo do tempo."
      ],
      "metadata": {
        "id": "VAdnyxPSTPUT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Cálculo da matriz de confusão\n",
        "y_true = y_true_val  # Rótulos verdadeiros de validação\n",
        "y_pred = y_pred_val  # Rótulos previstos\n",
        "\n",
        "conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
        "             xticklabels=['Negativo', 'Neutro', 'Positivo'],\n",
        "             yticklabels=['Negativo', 'Neutro', 'Positivo'])\n",
        "plt.ylabel('Rótulos Verdadeiros')\n",
        "plt.xlabel('Rótulos Previsto')\n",
        "plt.title('Matriz de Confusão')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "imVD8LsKIVuw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Criar o Trainer\n",
        "\n",
        "configura e inicia o treinamento do modelo BERT para classificação de sentimentos usando a biblioteca transformers\n"
      ],
      "metadata": {
        "id": "daTW-BwKpw_Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# métricas de desempenho do modelo no conjunto de dados de **avaliação**"
      ],
      "metadata": {
        "id": "rPZn8AY-5eMQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "AVALIAÇÃO"
      ],
      "metadata": {
        "id": "nkyoFe5hkZ_j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(train_losses, label='Training Loss', color='blue')\n",
        "plt.plot(eval_losses, label='Validation Loss', color='orange')\n",
        "plt.title('Loss over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "cr7ycbcOk6Xc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gráfico de Barras para a Distribuição de Sentimentos"
      ],
      "metadata": {
        "id": "7ZizTaaLGZAB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Supondo que a coluna 'label' contém 0 (Negativo), 1 (Positivo), e 2 (Neutro)\n",
        "sentiment_counts = df_PREFEITO['sentiment'].value_counts()\n",
        "\n",
        "# Configurações do gráfico\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.barplot(x=sentiment_counts.index, y=sentiment_counts.values, palette='viridis')\n",
        "plt.title('Distribuição de Sentimentos')\n",
        "plt.xlabel('Sentimento')\n",
        "plt.ylabel('Quantidade de Textos')\n",
        "plt.xticks(ticks=[0, 1, 2], labels=['Negativo', 'Positivo', 'Neutro'])\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "KYlBE0XZGYXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gráfico de Linha para Evolução Temporal dos Sentimentos\n"
      ],
      "metadata": {
        "id": "cTpVetTVGeF2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nuvem de Palavras"
      ],
      "metadata": {
        "id": "1UXoK3eoGhct"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud\n",
        "\n",
        "# Exemplo para sentimentos positivos\n",
        "positive_texts = ' '.join(df_PREFEITO[df_PREFEITO['sentiment'] == 1]['cleaned_text'])\n",
        "\n",
        "# Gerar nuvem de palavras\n",
        "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(positive_texts)\n",
        "\n",
        "# Configurações do gráfico\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.title('Nuvem de Palavras para Textos Positivos')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "SEFYWVD1Gica"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verifique se 'positive_texts' tem conteúdo\n",
        "print(positive_texts)\n",
        "print(\"Número de textos positivos:\", len(positive_texts))\n"
      ],
      "metadata": {
        "id": "gxaqWMSOlOL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Matriz de Confusão\n"
      ],
      "metadata": {
        "id": "vhnx3JbGGlOj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "# Suponha que y_true são os rótulos verdadeiros e y_pred as previsões do modelo\n",
        "conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# Configurações do gráfico\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Negativo', 'Positivo', 'Neutro'], yticklabels=['Negativo', 'Positivo', 'Neutro'])\n",
        "plt.title('Matriz de Confusão')\n",
        "plt.xlabel('Previsões')\n",
        "plt.ylabel('Valores Reais')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "_qMnVLFwGkgD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gráfico de Perda e Acurácia do Modelo"
      ],
      "metadata": {
        "id": "BMs_MXgeGq3f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exemplo simples de visualização da perda (loss) ao longo das épocas\n",
        "epochs = [1, 2, 3]  # Substituir pelos valores reais\n",
        "training_loss = [0.5, 0.25, 0.15]  # Substituir pelos valores reais\n",
        "validation_loss = [0.55, 0.30, 0.20]  # Substituir pelos valores reais\n",
        "\n",
        "# Configurações do gráfico\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.plot(epochs, training_loss, label='Perda de Treinamento', marker='o')\n",
        "plt.plot(epochs, validation_loss, label='Perda de Validação', marker='o')\n",
        "plt.title('Evolução da Perda Durante o Treinamento')\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Perda (Loss)')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "HaqZb52AGrQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. Gráfico de Dispersão 3D\n",
        "\n",
        "Se você tem mais variáveis numéricas no seu dataset, o heatmap de correlação pode ser útil para identificar relações entre elas."
      ],
      "metadata": {
        "id": "J_tStSJ6I9Cd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "# Supondo que você já tem embeddings (vetores) para cada texto\n",
        "# Redução de dimensionalidade para 3D usando PCA\n",
        "pca = PCA(n_components=3)\n",
        "reduced_embeddings = pca.fit_transform(text_embeddings)  # Substitua 'text_embeddings' pelos vetores reais\n",
        "\n",
        "# Configurações do gráfico\n",
        "fig = plt.figure(figsize=(10,8))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "scatter = ax.scatter(reduced_embeddings[:,0], reduced_embeddings[:,1], reduced_embeddings[:,2], c=df_concatenado['label'], cmap='viridis')\n",
        "\n",
        "# Adicionar legenda e rótulos\n",
        "legend = ax.legend(*scatter.legend_elements(), title=\"Sentimento\")\n",
        "ax.add_artist(legend)\n",
        "ax.set_title('Visualização 3D de Textos em Embeddings')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "6OqdJ_KBI2TQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Heatmap de Correlação Entre Variáveis\n",
        "Se você tem mais variáveis numéricas no seu dataset, o heatmap de correlação pode ser útil para identificar relações entre elas.\n",
        "\n"
      ],
      "metadata": {
        "id": "2Me6PgWEIbgC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exemplo para calcular a correlação e gerar o heatmap\n",
        "corr = df_concatenado[['text_length', 'label']].corr()\n",
        "\n",
        "# Configurações do gráfico\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(corr, annot=True, cmap='coolwarm', fmt='.2f')\n",
        "plt.title('Mapa de Calor das Correlações Entre Variáveis')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "HKGwPPHYHEsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gráfico de ROC (Receiver Operating Characteristic)\n",
        "Esse gráfico é utilizado para avaliar o desempenho do modelo de classificação. Ele mostra a relação entre a taxa de verdadeiros positivos e a taxa de falsos positivos."
      ],
      "metadata": {
        "id": "lgygoBe4HQuL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Learning Curve (Curva de Aprendizado)\n",
        "A curva de aprendizado ajuda a entender se o modelo está se ajustando bem ou sofrendo de overfitting ou underfitting."
      ],
      "metadata": {
        "id": "9lRUM0bdHnsL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import learning_curve\n",
        "\n",
        "# Gerando a curva de aprendizado\n",
        "train_sizes, train_scores, test_scores = learning_curve(model, X, y, cv=5, n_jobs=-1, train_sizes=np.linspace(0.1, 1.0, 5))\n",
        "\n",
        "# Calculando as médias e desvios padrão\n",
        "train_scores_mean = np.mean(train_scores, axis=1)\n",
        "test_scores_mean = np.mean(test_scores, axis=1)\n",
        "\n",
        "# Configurações do gráfico\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.plot(train_sizes, train_scores_mean, label='Pontuação de Treinamento', color='blue', marker='o')\n",
        "plt.plot(train_sizes, test_scores_mean, label='Pontuação de Validação', color='green', marker='o')\n",
        "plt.title('Curva de Aprendizado')\n",
        "plt.xlabel('Tamanho do Treinamento')\n",
        "plt.ylabel('Pontuação')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "OpmBVQOiHm6b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gráfico de Acurácia por Época\n",
        "Visualize a acurácia de validação ao longo das épocas para entender a evolução do desempenho do modelo.\n",
        "\n"
      ],
      "metadata": {
        "id": "xBh9MFWDHtSB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exemplo simples para plotar a acurácia ao longo das épocas\n",
        "epochs = [1, 2, 3]  # Substitua pelos valores reais\n",
        "accuracy = [0.82, 0.85, 0.88]  # Substitua pelos valores reais\n",
        "\n",
        "# Configurações do gráfico\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.plot(epochs, accuracy, label='Acurácia de Validação', marker='o', color='b')\n",
        "plt.title('Evolução da Acurácia Durante o Treinamento')\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Acurácia')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "tNcWdcACHwD_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}