{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNUqQN+W6nFP53qwsaDFEVa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carolineoliveira994/100-days-of-code-python/blob/main/TCC_TESTE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate\n",
        "!pip install python-dotenv\n",
        "!pip install spacy textblob\n",
        "!python -m textblob.download_corpora\n",
        "!python -m spacy download pt_core_news_sm  # Modelo em português\n",
        "!pip install unidecode\n",
        "\n",
        "!pip install unidecode nltk spacy\n",
        "!python -m spacy download pt_core_news_sm\n"
      ],
      "metadata": {
        "id": "iIRcujxg6Ttu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import evaluate\n",
        "from dotenv import load_dotenv\n",
        "import spacy\n",
        "import re\n",
        "import unidecode\n",
        "from textblob import TextBlob\n",
        "from nltk.stem import SnowballStemmer\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "import torch\n",
        "from google.colab import files\n",
        "from google.colab import auth\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"Diretório atual:\", os.getcwd())"
      ],
      "metadata": {
        "id": "jJUnZI496N5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WvkMFiP3vAsA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Coleta de dados usando a API da Bluesky\n",
        "\n",
        "\n",
        "**Objetivo**: Obter dados relevantes de postagens, comentários e interações na rede social Bluesky, focando em sentimentos relacionados às eleições de 2024.\n",
        "\n",
        "**Fontes de Dados**: Bluesky.\n",
        "\n",
        "**Técnicas de Coleta:** API do ATProtocol para interagir com os servidores Bluesky.\n",
        "\n",
        "**Autenticação**: Realizar a autenticação necessária para acessar a API, salvar credenciais no arquito .env.\n",
        "\n",
        "**Requisições HTTP:** Endpoints específicos da API que permitem obter postagens, comentários e perfis de usuários.\n",
        "\n",
        "PALAVRAS CHAVES: ELEIÇÕES, CANDITADOS, BOULOS, TABATA, DATENA...\n",
        "\n",
        "**Período de Coleta**: JUNHO.\n"
      ],
      "metadata": {
        "id": "5MlaxnCfs3Ro"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "nrkdzu6FrdZT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Packages:"
      ],
      "metadata": {
        "id": "sWiE_VsXvJp1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XrTiJrTIbOKJ"
      },
      "outputs": [],
      "source": [
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JX8HyCgDvolW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('.env', 'w') as f:\n",
        "    f.write(\"\"\"\n",
        "BLUESKY_APP_USER = 'cocorolini.bsky.social'\n",
        "BLUESKY_APP_PASS='3ovj-gbnh-trwd-k66r'\n",
        "\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "zs6iabB95QHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Busca no BLUESKY com a palavra chave \"ELEIÇÕES\""
      ],
      "metadata": {
        "id": "LJkfVJ5rwFGh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py search POLITICA --sort latest --limit 90\n"
      ],
      "metadata": {
        "id": "1pHULWJI5TTE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cria DataFrame"
      ],
      "metadata": {
        "id": "J3vrlGg-wIEP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = './data/search_results_POLITICA_2024_09_22.csv'\n",
        "df_POLITICA = pd.read_csv(file_path)\n",
        "df_POLITICA"
      ],
      "metadata": {
        "id": "C4-_YysA5VQ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lista DataFrame criados"
      ],
      "metadata": {
        "id": "aJTVuhxAwMsZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe_names = [name for name, obj in globals().items() if isinstance(obj, pd.DataFrame)]\n",
        "print(dataframe_names)"
      ],
      "metadata": {
        "id": "XIwurn5p66NV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Junta os DataFrames\n",
        "\n"
      ],
      "metadata": {
        "id": "XGhfGpuSwRYA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataframes = [\"df_boulos\", \"df_guilhermeboulos\", \"df_tabata\", \"df_tabataamaral\", \"df_novo\", \"df_altino\",\n",
        "             \"df_marçal\", \"df_bebeto\", \"df_datena\", \"df_RicardoNunes\", \"df_RICARDONUNES\", \"df_MDB\",\n",
        "             \"df_GuilhermeBoulos\", \"df_BOULOS\", \"df_PSOL\", \"df_PabloMarçal\", \"df_PRTB\", \"df_TabataAmaral\",\n",
        "             \"df_amaral\", \"df_PSB\", \"df_Datena\", \"df_DATENA\", \"df_PSDB\", \"df_PREFEITO\", \"_74\", \"df_CANDIDATO\",\n",
        "             \"_77\", \"df_ELEITORAL\", \"df_VOTO\", \"df_POLITICA\"]\n",
        "\n",
        "dataframes_to_concat = [globals()[name] for name in dataframes if name in globals()]\n",
        "\n",
        "df_concatenado = pd.concat(dataframes_to_concat, ignore_index=True)\n",
        "print(df_concatenado)"
      ],
      "metadata": {
        "id": "gN6qTCjYHuCH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_W3UT2WGIwie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_concatenado"
      ],
      "metadata": {
        "id": "ukIr_XUFHkMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remover colunas não ultilizadas"
      ],
      "metadata": {
        "id": "N3dnOmzkwfcG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_remove = [\"reply_count\", \"author_display_name\", \"author_handle\", \"indexed_at\", \"cid\", \"uri\", \"created_at\", \"repost_count\", \"like_count\"]\n",
        "df_concatenado = df_concatenado.drop(columns=columns_to_remove)\n",
        "\n",
        "print(\"\\nDepois:\")\n",
        "print(df_concatenado)\n"
      ],
      "metadata": {
        "id": "cKAa0Sv9JgES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "vc6D1jhMJ4EM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Limpeza: Remoção de stop words: Palavras comuns que não adicionam significado (ex: \"a\", \"o\", \"de\").\n",
        "Remoção de pontuação: Pontuação pode interferir na análise.\n",
        "Remoção de números: Se não forem relevantes para a análise de sentimentos.\n",
        "Correção de erros de digitação: Utilizando técnicas de correção ortográfica."
      ],
      "metadata": {
        "id": "-1_kWvYvKgtz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Autenticação hugg****ntirar"
      ],
      "metadata": {
        "id": "AVIYDADkwk10"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "os.environ['HF_TOKEN'] = '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'\n"
      ],
      "metadata": {
        "id": "pZ-eMcvDP2bn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparar o BERT para análise de sentimentos com três rótulos (positivo, negativo e neutro)"
      ],
      "metadata": {
        "id": "imnbIZ1-wunc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased')\n",
        "model = BertForSequenceClassification.from_pretrained('neuralmind/bert-base-portuguese-cased', num_labels=3)\n"
      ],
      "metadata": {
        "id": "n0W6A385NkOC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_concatenado['label'].unique())\n"
      ],
      "metadata": {
        "id": "Fx3-TA7lPRBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fluxo de Pré-processamento com spaCy\n",
        "\n",
        "* Remoção de URLs.\n",
        "* Remoção de menções.\n",
        "* Remoção de hashtags.\n",
        "* Remoção de números.\n",
        "* Remoção de acentos.\n",
        "* Conversão para minúsculas\n",
        "* Lematização e remoção de stop words e pontuação: Usa o spaCy para remover stop words e pontuação e retorna o texto lematizado.\n"
      ],
      "metadata": {
        "id": "1hyGhaLFxfGY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"pt_core_news_sm\")\n",
        "\n",
        "def clean_text(text):\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"  # Retorna uma string vazia se o texto não for string\n",
        "\n",
        "    # Remover URLs\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
        "\n",
        "    # Remover menções (@username)\n",
        "    text = re.sub(r'@\\w+', '', text)\n",
        "\n",
        "    # Remover hashtags (#hashtag)\n",
        "    text = re.sub(r'#\\w+', '', text)\n",
        "\n",
        "    # Remover números\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "\n",
        "    # Remover acentos\n",
        "    text = unidecode.unidecode(text)\n",
        "\n",
        "    # Converter para minúsculas\n",
        "    text = text.lower()\n",
        "\n",
        "    # Processar o texto com spaCy\n",
        "    doc = nlp(text)\n",
        "\n",
        "    # Remover stop words e pontuação\n",
        "    cleaned_text = ' '.join([token.lemma_ for token in doc if not token.is_stop and not token.is_punct])\n",
        "\n",
        "    return cleaned_text\n",
        "\n",
        "texts = df_concatenado['text'].tolist()\n",
        "cleaned_texts = [clean_text(text) for text in texts]\n",
        "\n",
        "df_concatenado['cleaned_text'] = cleaned_texts\n",
        "print(df_concatenado[['text', 'cleaned_text']].head())\n"
      ],
      "metadata": {
        "id": "pi06AHArKjVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "jlK4qJfbQlnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aplicar a função para rotular automaticamente os textos"
      ],
      "metadata": {
        "id": "SwLKDv59yHBh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Distribuição de Comprimento de Textos"
      ],
      "metadata": {
        "id": "jLrychjJID1b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular o comprimento de cada texto\n",
        "df_concatenado['text_length'] = df_concatenado['cleaned_text'].apply(lambda x: len(x.split()))\n",
        "\n",
        "# Configurações do gráfico\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.histplot(df_concatenado['text_length'], bins=30, kde=True, color='green')\n",
        "plt.title('Distribuição do Comprimento dos Textos')\n",
        "plt.xlabel('Número de Palavras')\n",
        "plt.ylabel('Frequência')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Lc7Vb9E3yqgK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definição das listas de palavras-chave (Features)"
      ],
      "metadata": {
        "id": "-pgEL10CyuyY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def label_text(text):\n",
        "    positive_keywords = ['ótimo', 'ótima', 'amor', 'amora', 'correto', 'coreta' 'incrível', 'incrível', 'sujo', 'suja', 'ganho', 'ganha', 'prefeito', 'prefeita', 'vencer', 'vencer', 'sucesso', 'sucesso', 'vote', 'vote', 'vitória', 'vitória', 'esperança', 'esperança', 'sorriso', 'sorriso', 'celebrar', 'celebrar', 'melhorar', 'melhorar', 'perfeito', 'perfeita', 'bom', 'boa', 'maravilhoso', 'maravilhosa', 'adoro', 'adoro', 'excelente', 'excelente', 'demais', 'demais', 'casa comigo', 'casa comigo', 'delícia', 'delícia', 'proposta', 'proposta', 'conhece', 'conhece', 'feliz', 'feliz', 'positivo', 'positiva', 'agradável', 'agradável', 'conquista', 'conquista', 'forte', 'forte', 'brilhante', 'brilhante', 'valioso', 'valiosa', 'benéfico', 'benéfica', 'grato', 'grata', 'aprimorar', 'aprimorar', 'jovial', 'jovial', 'vibrante', 'vibrante', 'cheio de vida', 'cheia de vida', 'vitalidade', 'vitalidade', 'tranquilo', 'tranquila', 'satisfatório', 'satisfatória', 'ansioso', 'ansiosa', 'animado', 'animada', 'compreensivo', 'compreensiva', 'carinhoso', 'carinhosa', 'amigável', 'amigável', 'determinado', 'determinada', 'fortalecer', 'fortalecer', 'aceitar', 'aceitar', 'progresso', 'progresso', 'união', 'união', 'alegria', 'alegria', 'bravo', 'brava', 'realizar', 'realizar', 'gentil', 'gentil', 'benigno', 'benigna', 'felicidade', 'felicidade', 'delicioso', 'deliciosa', 'apaixonado', 'apaixonada', 'otimismo', 'otimismo', 'cooperar', 'cooperar', 'triumphar', 'triumphar', 'jubilante', 'jubilante', 'extraordinário', 'extraordinária', 'esplêndido', 'esplêndida', 'efetivo', 'efetiva', 'fortalecedor', 'fortalecedora', 'resiliente', 'resiliente', 'serenidade', 'serenidade', 'pleno', 'plena', 'visionário', 'visionária', 'original', 'original', 'cativante', 'cativante', 'sincero', 'sincera', 'dedicado', 'dedicada', 'ousado', 'ousada', 'alegre', 'alegre', 'sereno', 'serena', 'gracioso', 'graciosa', 'próspero', 'próspera', 'compassivo', 'compassiva', 'energizante', 'energizante', 'instigante', 'instigante', 'transformador', 'transformadora', 'animador', 'animadora', 'caridade', 'caridade', 'generoso', 'generosa', 'estudioso', 'estudiosa']\n",
        "    negative_keywords = ['manipulação', 'inutil', 'trouxa', 'farsante', 'ruim', 'horrível', 'pior', 'não recomendo', 'credo', 'vagabundo', 'vagabunda', 'nojo', 'odiar', 'desapontar', 'quebrar', 'perder', 'ignorar', 'negar', 'fracassar', 'destruir', 'desfavoritar', 'desencorajar', 'fracasso', 'desespero', 'problema', 'dificuldade', 'raiva', 'tristeza', 'crítica', 'frustração', 'desilusão', 'desânimo', 'decepcionante', 'terrível', 'insatisfatório', 'chato', 'chata', 'aborrecido', 'aborrecida', 'desagradável', 'desastroso', 'desastrosa', 'incapaz', 'fraco', 'fraca', 'desapontador', 'desapontadora', 'chateado', 'chateada', 'injusto', 'injusta', 'mal', 'tenso', 'tensa', 'descontentamento', 'fracassado', 'fracassada', 'abandonado', 'abandonada', 'desesperado', 'desesperada', 'angustiante', 'inadequado', 'inadequada', 'infeliz', 'irritante', 'desprezível', 'desfavorável', 'hostil', 'dificultoso', 'insuficiente', 'arrogante', 'triste', 'crueldade', 'injustiça', 'desgosto', 'aflição', 'desprezo', 'inseguro', 'insegura', 'abominável', 'afrontoso', 'afrontosa', 'dissonante', 'constrangedor', 'constrangedora', 'frustrante', 'pessimista', 'insatisfação', 'fúria', 'rejeição', 'desfavor', 'maléfico', 'maléfica', 'dano', 'deprimente', 'perturbador', 'perturbadora', 'ruína', 'fiasco', 'afronta', 'cárcere', 'desventurado', 'desventurada', 'desgrace', 'desolador', 'desoladora', 'tóxico', 'tóxica', 'trágico', 'trágica', 'desaparecimento', 'caos', 'medo', 'perturbação', 'hostilidade', 'destruição']\n",
        "\n",
        "    if any(word in text for word in positive_keywords):\n",
        "        return 1  # Positivo\n",
        "    elif any(word in text for word in negative_keywords):\n",
        "        return 0  # Negativo\n",
        "    else:\n",
        "        return 2  # Neutro ou indefinido\n",
        "\n",
        "df_concatenado['label'] = df_concatenado['cleaned_text'].apply(label_text)\n",
        "\n",
        "print(df_concatenado[['text', 'cleaned_text', 'label']])"
      ],
      "metadata": {
        "id": "kHMnw9Y8LgIr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_concatenado"
      ],
      "metadata": {
        "id": "Chem4r75Vk3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "train_test_split da biblioteca sklearn é utilizada para dividir os dados em duas partes, uma para treinamento do modelo e outra para avaliação teste\n",
        "\n",
        "mportância da Divisão Estratificada:\n",
        "Como você está lidando com um problema de análise de sentimentos com três rótulos (positivo, negativo, neutro), é importante garantir que o modelo veja uma proporção representativa de cada classe durante o treinamento e também durante a avaliação. Isso é especialmente relevante quando as classes são desbalanceadas, como no seu caso (com muito mais instâncias positivas do que negativas e neutras).\n",
        "\n",
        "Exemplo Prático:\n",
        "Se você tem um total de 2641 instâncias no DataFrame df_concatenado, a divisão estratificada irá garantir algo como:\n",
        "\n",
        "Treinamento: Aproximadamente 2112 instâncias (80% do total), distribuídas de maneira proporcional aos rótulos.\n",
        "Avaliação: Aproximadamente 529 instâncias (20% do total), também com a mesma distribuição proporcional."
      ],
      "metadata": {
        "id": "LMwOkQXxzsb1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, eval_df = train_test_split(df_concatenado, test_size=0.2, random_state=42, stratify=df_concatenado['label'])\n",
        "\n",
        "print(\"Dados de Treinamento:\")\n",
        "print(train_df.head())\n",
        "print(\"\\nDados de Avaliação:\")\n",
        "print(eval_df.head())\n"
      ],
      "metadata": {
        "id": "JtrshX7zaZ9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_concatenado['label'].value_counts())\n"
      ],
      "metadata": {
        "id": "6iRTqTN7a2yV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_concatenado['label'].value_counts())\n"
      ],
      "metadata": {
        "id": "e29sab76gT3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim\n",
        "!pip install nltk\n",
        "!pip install pandas\n"
      ],
      "metadata": {
        "id": "FXCasPiM0u5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenizar os textos usando o BERT em português\n",
        "\n",
        "**input_ids**: IDs numéricos correspondentes aos tokens do texto.\n",
        "\n",
        "**attention_mask**: Máscara de atenção que indica quais tokens são reais e quais são padding (zeros)."
      ],
      "metadata": {
        "id": "cudGJiMt01ZH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased')\n",
        "\n",
        "def tokenize_function(texts):\n",
        "    return tokenizer(texts, padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")\n",
        "\n",
        "train_encodings = tokenize_function(train_df['cleaned_text'].tolist())\n",
        "eval_encodings = tokenize_function(eval_df['cleaned_text'].tolist())\n"
      ],
      "metadata": {
        "id": "a4TCF2JpgX_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "teste"
      ],
      "metadata": {
        "id": "D8JkT0jVViyU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "import re\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove caracteres especiais\n",
        "    text = text.lower()  # Converte para minúsculas\n",
        "    tokens = word_tokenize(text)  # Tokenização\n",
        "    return tokens\n",
        "\n",
        "df_concatenado['tokens'] = df_concatenado['cleaned_text'].apply(preprocess_text)\n"
      ],
      "metadata": {
        "id": "hnm-I5t-p42a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "# Treinamento do modelo Word2Vec\n",
        "model = Word2Vec(sentences=df_concatenado['tokens'].tolist(), vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "# Salvar o modelo\n",
        "model.save(\"word2vec.model\")\n"
      ],
      "metadata": {
        "id": "8lbnawAVWShh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def vectorize_sentence(tokens):\n",
        "    vectors = []\n",
        "    for token in tokens:\n",
        "        if token in model.wv:\n",
        "            vectors.append(model.wv[token])\n",
        "    return np.mean(vectors, axis=0) if vectors else np.zeros(model.vector_size)\n",
        "\n",
        "df_concatenado['sentence_vector'] = df_concatenado['tokens'].apply(vectorize_sentence)\n"
      ],
      "metadata": {
        "id": "7g0jp-VFWkRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "X = list(df_concatenado['sentence_vector'])\n",
        "y = df_concatenado['label']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Treinamento do classificador\n",
        "classifier = SVC()\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Previsão\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Avaliação\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "tEHYXpl4Wspw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1, 2])\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "4bv6TPonXHWN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Definir o SentimentDataset e os loaders de dados de treinamento e avaliação.\n",
        "\n",
        "**SentimentDataset**: organiza os dados de entrada (codificações e rótulos) para que possam ser usados pelo modelo.\n",
        "\n",
        "**DataLoader**: facilita o carregamento dos dados em lotes para alimentar o modelo durante o treinamento e a avaliação."
      ],
      "metadata": {
        "id": "Q6Oa8hOR1W9L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "class SentimentDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = SentimentDataset(train_encodings, train_df['label'].tolist())\n",
        "eval_dataset = SentimentDataset(eval_encodings, eval_df['label'].tolist())\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "eval_loader = DataLoader(eval_dataset, batch_size=8, shuffle=False)\n"
      ],
      "metadata": {
        "id": "seVXyhnegaz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configuração do ambiente de treinamento, permitindo o controle sobre o processo de otimização, salvamento de modelos e avaliação, garantindo o monitoraramento do desempenho ao longo do tempo."
      ],
      "metadata": {
        "id": "VAdnyxPSTPUT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',          # Diretório onde os resultados serão salvos\n",
        "    num_train_epochs=3,              # Número de épocas\n",
        "    per_device_train_batch_size=8,   # Tamanho do lote para treinamento\n",
        "    per_device_eval_batch_size=8,    # Tamanho do lote para avaliação\n",
        "    warmup_steps=500,                 # Número de passos para warmup\n",
        "    weight_decay=0.01,               # Taxa de decaimento de peso\n",
        "    logging_dir='./logs',            # Diretório para logs\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy=\"epoch\",      # Avaliação após cada época\n",
        ")\n"
      ],
      "metadata": {
        "id": "agCpg-9hceJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Criar o Trainer\n",
        "\n",
        "configura e inicia o treinamento do modelo BERT para classificação de sentimentos usando a biblioteca transformers\n"
      ],
      "metadata": {
        "id": "daTW-BwKpw_Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer, BertForSequenceClassification\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained('neuralmind/bert-base-portuguese-cased', num_labels=3) #modelo BERT pré-treinado específico para a língua portuguesa\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset, #conjunto de dados de treinamento a ser utilizado\n",
        "    eval_dataset=eval_dataset     #conjunto de dados de avaliação para monitorar o desempenho do modelo durante o treinamento\n",
        ")\n"
      ],
      "metadata": {
        "id": "Fu-qJlR1goZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()\n"
      ],
      "metadata": {
        "id": "ovGO9iXngqEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# métricas de desempenho do modelo no conjunto de dados de **avaliação**"
      ],
      "metadata": {
        "id": "rPZn8AY-5eMQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate()\n"
      ],
      "metadata": {
        "id": "Rh7hxw8VgrUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained('./model')\n",
        "tokenizer.save_pretrained('./model')\n"
      ],
      "metadata": {
        "id": "l3Z3WUbJgtSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "AVALIAÇÃO"
      ],
      "metadata": {
        "id": "nkyoFe5hkZ_j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(train_losses, label='Training Loss', color='blue')\n",
        "plt.plot(eval_losses, label='Validation Loss', color='orange')\n",
        "plt.title('Loss over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "cr7ycbcOk6Xc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gráfico de Barras para a Distribuição de Sentimentos"
      ],
      "metadata": {
        "id": "7ZizTaaLGZAB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Supondo que a coluna 'label' contém 0 (Negativo), 1 (Positivo), e 2 (Neutro)\n",
        "sentiment_counts = df_concatenado['label'].value_counts()\n",
        "\n",
        "# Configurações do gráfico\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.barplot(x=sentiment_counts.index, y=sentiment_counts.values, palette='viridis')\n",
        "plt.title('Distribuição de Sentimentos')\n",
        "plt.xlabel('Sentimento')\n",
        "plt.ylabel('Quantidade de Textos')\n",
        "plt.xticks(ticks=[0, 1, 2], labels=['Negativo', 'Positivo', 'Neutro'])\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "KYlBE0XZGYXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gráfico de Linha para Evolução Temporal dos Sentimentos\n"
      ],
      "metadata": {
        "id": "cTpVetTVGeF2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nuvem de Palavras"
      ],
      "metadata": {
        "id": "1UXoK3eoGhct"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud\n",
        "\n",
        "# Exemplo para sentimentos positivos\n",
        "positive_texts = ' '.join(df_concatenado[df_concatenado['label'] == 1]['cleaned_text'])\n",
        "\n",
        "# Gerar nuvem de palavras\n",
        "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(positive_texts)\n",
        "\n",
        "# Configurações do gráfico\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.title('Nuvem de Palavras para Textos Positivos')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "SEFYWVD1Gica"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Matriz de Confusão\n"
      ],
      "metadata": {
        "id": "vhnx3JbGGlOj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "# Suponha que y_true são os rótulos verdadeiros e y_pred as previsões do modelo\n",
        "conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# Configurações do gráfico\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Negativo', 'Positivo', 'Neutro'], yticklabels=['Negativo', 'Positivo', 'Neutro'])\n",
        "plt.title('Matriz de Confusão')\n",
        "plt.xlabel('Previsões')\n",
        "plt.ylabel('Valores Reais')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "_qMnVLFwGkgD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gráfico de Perda e Acurácia do Modelo"
      ],
      "metadata": {
        "id": "BMs_MXgeGq3f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exemplo simples de visualização da perda (loss) ao longo das épocas\n",
        "epochs = [1, 2, 3]  # Substituir pelos valores reais\n",
        "training_loss = [0.5, 0.25, 0.15]  # Substituir pelos valores reais\n",
        "validation_loss = [0.55, 0.30, 0.20]  # Substituir pelos valores reais\n",
        "\n",
        "# Configurações do gráfico\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.plot(epochs, training_loss, label='Perda de Treinamento', marker='o')\n",
        "plt.plot(epochs, validation_loss, label='Perda de Validação', marker='o')\n",
        "plt.title('Evolução da Perda Durante o Treinamento')\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Perda (Loss)')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "HaqZb52AGrQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. Gráfico de Dispersão 3D\n",
        "\n",
        "Se você tem mais variáveis numéricas no seu dataset, o heatmap de correlação pode ser útil para identificar relações entre elas."
      ],
      "metadata": {
        "id": "J_tStSJ6I9Cd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "# Supondo que você já tem embeddings (vetores) para cada texto\n",
        "# Redução de dimensionalidade para 3D usando PCA\n",
        "pca = PCA(n_components=3)\n",
        "reduced_embeddings = pca.fit_transform(text_embeddings)  # Substitua 'text_embeddings' pelos vetores reais\n",
        "\n",
        "# Configurações do gráfico\n",
        "fig = plt.figure(figsize=(10,8))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "scatter = ax.scatter(reduced_embeddings[:,0], reduced_embeddings[:,1], reduced_embeddings[:,2], c=df_concatenado['label'], cmap='viridis')\n",
        "\n",
        "# Adicionar legenda e rótulos\n",
        "legend = ax.legend(*scatter.legend_elements(), title=\"Sentimento\")\n",
        "ax.add_artist(legend)\n",
        "ax.set_title('Visualização 3D de Textos em Embeddings')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "6OqdJ_KBI2TQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Heatmap de Correlação Entre Variáveis\n",
        "Se você tem mais variáveis numéricas no seu dataset, o heatmap de correlação pode ser útil para identificar relações entre elas.\n",
        "\n"
      ],
      "metadata": {
        "id": "2Me6PgWEIbgC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exemplo para calcular a correlação e gerar o heatmap\n",
        "corr = df_concatenado[['text_length', 'label']].corr()\n",
        "\n",
        "# Configurações do gráfico\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(corr, annot=True, cmap='coolwarm', fmt='.2f')\n",
        "plt.title('Mapa de Calor das Correlações Entre Variáveis')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "HKGwPPHYHEsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gráfico de ROC (Receiver Operating Characteristic)\n",
        "Esse gráfico é utilizado para avaliar o desempenho do modelo de classificação. Ele mostra a relação entre a taxa de verdadeiros positivos e a taxa de falsos positivos."
      ],
      "metadata": {
        "id": "lgygoBe4HQuL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Learning Curve (Curva de Aprendizado)\n",
        "A curva de aprendizado ajuda a entender se o modelo está se ajustando bem ou sofrendo de overfitting ou underfitting."
      ],
      "metadata": {
        "id": "9lRUM0bdHnsL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import learning_curve\n",
        "\n",
        "# Gerando a curva de aprendizado\n",
        "train_sizes, train_scores, test_scores = learning_curve(model, X, y, cv=5, n_jobs=-1, train_sizes=np.linspace(0.1, 1.0, 5))\n",
        "\n",
        "# Calculando as médias e desvios padrão\n",
        "train_scores_mean = np.mean(train_scores, axis=1)\n",
        "test_scores_mean = np.mean(test_scores, axis=1)\n",
        "\n",
        "# Configurações do gráfico\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.plot(train_sizes, train_scores_mean, label='Pontuação de Treinamento', color='blue', marker='o')\n",
        "plt.plot(train_sizes, test_scores_mean, label='Pontuação de Validação', color='green', marker='o')\n",
        "plt.title('Curva de Aprendizado')\n",
        "plt.xlabel('Tamanho do Treinamento')\n",
        "plt.ylabel('Pontuação')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "OpmBVQOiHm6b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gráfico de Acurácia por Época\n",
        "Visualize a acurácia de validação ao longo das épocas para entender a evolução do desempenho do modelo.\n",
        "\n"
      ],
      "metadata": {
        "id": "xBh9MFWDHtSB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exemplo simples para plotar a acurácia ao longo das épocas\n",
        "epochs = [1, 2, 3]  # Substitua pelos valores reais\n",
        "accuracy = [0.82, 0.85, 0.88]  # Substitua pelos valores reais\n",
        "\n",
        "# Configurações do gráfico\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.plot(epochs, accuracy, label='Acurácia de Validação', marker='o', color='b')\n",
        "plt.title('Evolução da Acurácia Durante o Treinamento')\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Acurácia')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "tNcWdcACHwD_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}