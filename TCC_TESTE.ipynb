{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPsVsZmrOrTsetriHMhlNOL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carolineoliveira994/100-days-of-code-python/blob/main/TCC_TESTE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate\n",
        "!pip install python-dotenv\n",
        "!pip install spacy textblob\n",
        "!python -m textblob.download_corpora\n",
        "!python -m spacy download pt_core_news_sm  # Modelo em português\n",
        "!pip install unidecode\n",
        "\n",
        "!pip install unidecode nltk spacy\n",
        "!python -m spacy download pt_core_news_sm\n"
      ],
      "metadata": {
        "id": "iIRcujxg6Ttu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import evaluate\n",
        "from dotenv import load_dotenv\n",
        "import spacy\n",
        "import re\n",
        "import unidecode\n",
        "from textblob import TextBlob\n",
        "from nltk.stem import SnowballStemmer\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "import torch\n",
        "from google.colab import files\n",
        "from google.colab import auth\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"Diretório atual:\", os.getcwd())"
      ],
      "metadata": {
        "id": "jJUnZI496N5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WvkMFiP3vAsA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Coleta de dados usando a API da Bluesky\n",
        "\n",
        "\n",
        "**Objetivo**: Obter dados relevantes de postagens, comentários e interações na rede social Bluesky, focando em sentimentos relacionados às eleições de 2024.\n",
        "\n",
        "**Fontes de Dados**: Bluesky.\n",
        "\n",
        "**Técnicas de Coleta:** API do ATProtocol para interagir com os servidores Bluesky.\n",
        "\n",
        "**Autenticação**: Realizar a autenticação necessária para acessar a API, salvar credenciais no arquito .env.\n",
        "\n",
        "**Requisições HTTP:** Endpoints específicos da API que permitem obter postagens, comentários e perfis de usuários.\n",
        "\n",
        "PALAVRAS CHAVES: ELEIÇÕES, CANDITADOS, BOULOS, TABATA, DATENA...\n",
        "\n",
        "**Período de Coleta**: JUNHO.\n"
      ],
      "metadata": {
        "id": "5MlaxnCfs3Ro"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "nrkdzu6FrdZT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Packages:"
      ],
      "metadata": {
        "id": "sWiE_VsXvJp1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XrTiJrTIbOKJ"
      },
      "outputs": [],
      "source": [
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JX8HyCgDvolW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('.env', 'w') as f:\n",
        "    f.write(\"\"\"\n",
        "BLUESKY_APP_USER = 'cocorolini.bsky.social'\n",
        "BLUESKY_APP_PASS='3ovj-gbnh-trwd-k66r'\n",
        "\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "zs6iabB95QHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Busca no BLUESKY com a palavra chave \"ELEIÇÕES\""
      ],
      "metadata": {
        "id": "LJkfVJ5rwFGh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py search ELEICOES --sort latest --limit 90\n"
      ],
      "metadata": {
        "id": "1pHULWJI5TTE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cria DataFrame"
      ],
      "metadata": {
        "id": "J3vrlGg-wIEP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = './data/search_results_ELEICOES_2024_09_25.csv'\n",
        "df_PREFEITO = pd.read_csv(file_path)\n",
        "df_PREFEITO"
      ],
      "metadata": {
        "id": "C4-_YysA5VQ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lista DataFrame criados"
      ],
      "metadata": {
        "id": "aJTVuhxAwMsZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe_names = [name for name, obj in globals().items() if isinstance(obj, pd.DataFrame)]\n",
        "print(dataframe_names)"
      ],
      "metadata": {
        "id": "XIwurn5p66NV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Junta os DataFrames\n",
        "\n"
      ],
      "metadata": {
        "id": "XGhfGpuSwRYA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataframes = [\"df_boulos\", \"df_guilhermeboulos\", \"df_tabata\", \"df_tabataamaral\", \"df_novo\", \"df_altino\",\n",
        "             \"df_marçal\", \"df_bebeto\", \"df_datena\", \"df_RicardoNunes\", \"df_RICARDONUNES\", \"df_MDB\",\n",
        "             \"df_GuilhermeBoulos\", \"df_BOULOS\", \"df_PSOL\", \"df_PabloMarçal\", \"df_PRTB\", \"df_TabataAmaral\",\n",
        "             \"df_amaral\", \"df_PSB\", \"df_Datena\", \"df_DATENA\", \"df_PSDB\", \"df_PREFEITO\", \"_74\", \"df_CANDIDATO\",\n",
        "             \"_77\", \"df_ELEITORAL\", \"df_VOTO\", \"df_POLITICA\"]\n",
        "\n",
        "dataframes_to_concat = [globals()[name] for name in dataframes if name in globals()]\n",
        "\n",
        "df_concatenado = pd.concat(dataframes_to_concat, ignore_index=True)\n",
        "print(df_concatenado)"
      ],
      "metadata": {
        "id": "gN6qTCjYHuCH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_W3UT2WGIwie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_PREFEITO"
      ],
      "metadata": {
        "id": "ukIr_XUFHkMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remover colunas não ultilizadas"
      ],
      "metadata": {
        "id": "N3dnOmzkwfcG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_remove = [\"reply_count\", \"author_display_name\", \"author_handle\", \"indexed_at\", \"cid\", \"uri\", \"created_at\", \"repost_count\", \"like_count\"]\n",
        "df_PREFEITO = df_PREFEITO.drop(columns=columns_to_remove)\n",
        "\n",
        "print(\"\\nDepois:\")\n",
        "print(df_PREFEITO)\n"
      ],
      "metadata": {
        "id": "cKAa0Sv9JgES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "vc6D1jhMJ4EM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Limpeza: Remoção de stop words: Palavras comuns que não adicionam significado (ex: \"a\", \"o\", \"de\").\n",
        "Remoção de pontuação: Pontuação pode interferir na análise.\n",
        "Remoção de números: Se não forem relevantes para a análise de sentimentos.\n",
        "Correção de erros de digitação: Utilizando técnicas de correção ortográfica."
      ],
      "metadata": {
        "id": "-1_kWvYvKgtz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Autenticação hugg****ntirar"
      ],
      "metadata": {
        "id": "AVIYDADkwk10"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "os.environ['HF_TOKEN'] = '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'\n"
      ],
      "metadata": {
        "id": "pZ-eMcvDP2bn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparar o BERT para análise de sentimentos com três rótulos (positivo, negativo e neutro)"
      ],
      "metadata": {
        "id": "imnbIZ1-wunc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased')\n",
        "model = BertForSequenceClassification.from_pretrained('neuralmind/bert-base-portuguese-cased', num_labels=3)\n"
      ],
      "metadata": {
        "id": "n0W6A385NkOC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_PREFEITO['label'].unique())\n"
      ],
      "metadata": {
        "id": "Fx3-TA7lPRBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fluxo de Pré-processamento com spaCy\n",
        "\n",
        "* Remoção de URLs.\n",
        "* Remoção de menções.\n",
        "* Remoção de hashtags.\n",
        "* Remoção de números.\n",
        "* Remoção de acentos.\n",
        "* Conversão para minúsculas\n",
        "* Lematização e remoção de stop words e pontuação: Usa o spaCy para remover stop words e pontuação e retorna o texto lematizado.\n"
      ],
      "metadata": {
        "id": "1hyGhaLFxfGY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"pt_core_news_sm\")\n",
        "\n",
        "def clean_text(text):\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"  # Retorna uma string vazia se o texto não for string\n",
        "\n",
        "    # Remover URLs\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
        "\n",
        "    # Remover menções (@username)\n",
        "    text = re.sub(r'@\\w+', '', text)\n",
        "\n",
        "    # Remover hashtags (#hashtag)\n",
        "    text = re.sub(r'#\\w+', '', text)\n",
        "\n",
        "    # Remover números\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "\n",
        "    # Remover acentos\n",
        "    text = unidecode.unidecode(text)\n",
        "\n",
        "    # Converter para minúsculas\n",
        "    text = text.lower()\n",
        "\n",
        "    # Processar o texto com spaCy\n",
        "    doc = nlp(text)\n",
        "\n",
        "    # Remover stop words e pontuação\n",
        "    cleaned_text = ' '.join([token.lemma_ for token in doc if not token.is_stop and not token.is_punct])\n",
        "\n",
        "    return cleaned_text\n",
        "\n",
        "texts = df_PREFEITO['text'].tolist()\n",
        "cleaned_texts = [clean_text(text) for text in texts]\n",
        "\n",
        "df_PREFEITO['cleaned_text'] = cleaned_texts\n",
        "print(df_PREFEITO[['text', 'cleaned_text']].head())\n"
      ],
      "metadata": {
        "id": "pi06AHArKjVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_PREFEITO.shape"
      ],
      "metadata": {
        "id": "jlK4qJfbQlnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aplicar a função para rotular automaticamente os textos"
      ],
      "metadata": {
        "id": "SwLKDv59yHBh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Distribuição de Comprimento de Textos"
      ],
      "metadata": {
        "id": "jLrychjJID1b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definição das listas de palavras-chave (Features)"
      ],
      "metadata": {
        "id": "-pgEL10CyuyY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from transformers import pipeline\n",
        "\n",
        "data = df_PREFEITO['cleaned_text']\n",
        "#Criar DataFrame\n",
        "df_PREFEITO = pd.DataFrame(data)\n",
        "\n",
        "# Carregar o pipeline de análise de sentimentos com modelo pré-treinado\n",
        "sentiment_pipeline = pipeline('sentiment-analysis', model='nlptown/bert-base-multilingual-uncased-sentiment')\n",
        "\n",
        "# Classificar sentimentos\n",
        "df_PREFEITO['sentiment'] = df_PREFEITO['cleaned_text'].apply(lambda x: sentiment_pipeline(x)[0]['label'])\n",
        "\n",
        "# Visualizar o DataFrame com os rótulos\n",
        "print(df_PREFEITO)\n"
      ],
      "metadata": {
        "id": "OGOKSKJhHuRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from transformers import pipeline\n",
        "\n",
        "# Carregar a coluna 'cleaned_text' do DataFrame\n",
        "data = df_PREFEITO['cleaned_text']\n",
        "df_PREFEITO = pd.DataFrame(data)\n",
        "\n",
        "# Carregar o pipeline de análise de sentimentos com modelo pré-treinado\n",
        "sentiment_pipeline = pipeline('sentiment-analysis', model='nlptown/bert-base-multilingual-uncased-sentiment')\n",
        "\n",
        "# Mapeamento dos rótulos para categorias\n",
        "label_mapping = {\n",
        "    '1 star': 'negativo',\n",
        "    '2 stars': 'negativo',\n",
        "    '3 stars': 'neutro',\n",
        "    '4 stars': 'positivo',\n",
        "    '5 stars': 'positivo'\n",
        "}\n",
        "\n",
        "# Classificar sentimentos e mapear para os rótulos desejados\n",
        "df_PREFEITO['sentiment'] = df_PREFEITO['cleaned_text'].apply(lambda x: label_mapping[sentiment_pipeline(x)[0]['label']])\n",
        "\n",
        "# Visualizar o DataFrame com os rótulos\n",
        "print(df_PREFEITO)\n"
      ],
      "metadata": {
        "id": "GBemsIl6Hh-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_PREFEITO"
      ],
      "metadata": {
        "id": "8NBvkvPtL-5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_concatenado"
      ],
      "metadata": {
        "id": "Chem4r75Vk3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "train_test_split da biblioteca sklearn é utilizada para dividir os dados em duas partes, uma para treinamento do modelo e outra para avaliação teste\n",
        "\n",
        "mportância da Divisão Estratificada:\n",
        "Como você está lidando com um problema de análise de sentimentos com três rótulos (positivo, negativo, neutro), é importante garantir que o modelo veja uma proporção representativa de cada classe durante o treinamento e também durante a avaliação. Isso é especialmente relevante quando as classes são desbalanceadas, como no seu caso (com muito mais instâncias positivas do que negativas e neutras).\n",
        "\n",
        "Exemplo Prático:\n",
        "Se você tem um total de 2641 instâncias no DataFrame df_concatenado, a divisão estratificada irá garantir algo como:\n",
        "\n",
        "Treinamento: Aproximadamente 2112 instâncias (80% do total), distribuídas de maneira proporcional aos rótulos.\n",
        "Avaliação: Aproximadamente 529 instâncias (20% do total), também com a mesma distribuição proporcional."
      ],
      "metadata": {
        "id": "LMwOkQXxzsb1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, eval_df = train_test_split(df_PREFEITO, test_size=0.2, random_state=42, stratify=df_PREFEITO['sentiment'])\n",
        "\n",
        "print(\"Dados de Treinamento:\")\n",
        "print(train_df.head())\n",
        "print(\"\\nDados de Avaliação:\")\n",
        "print(eval_df.head())\n"
      ],
      "metadata": {
        "id": "JtrshX7zaZ9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_PREFEITO['sentiment'].value_counts())\n"
      ],
      "metadata": {
        "id": "6iRTqTN7a2yV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim\n",
        "!pip install nltk\n",
        "!pip install pandas\n"
      ],
      "metadata": {
        "id": "FXCasPiM0u5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenizar os textos usando o BERT em português\n",
        "\n",
        "**input_ids**: IDs numéricos correspondentes aos tokens do texto.\n",
        "\n",
        "**attention_mask**: Máscara de atenção que indica quais tokens são reais e quais são padding (zeros)."
      ],
      "metadata": {
        "id": "cudGJiMt01ZH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Carregar o tokenizer do modelo pré-treinado em português\n",
        "tokenizer = BertTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased')\n",
        "\n",
        "# Função para tokenizar os textos\n",
        "def tokenize_function(texts):\n",
        "    return tokenizer(texts, padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")\n",
        "\n",
        "# Tokenizar os dados de treinamento e de avaliação\n",
        "train_encodings = tokenize_function(train_df['cleaned_text'].tolist())\n",
        "eval_encodings = tokenize_function(eval_df['cleaned_text'].tolist())\n",
        "\n",
        "# Exibir a estrutura dos encodings gerados\n",
        "print(train_encodings.keys())  # Mostra as chaves, como 'input_ids', 'attention_mask'\n",
        "print(eval_encodings.keys())\n"
      ],
      "metadata": {
        "id": "a4TCF2JpgX_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "teste"
      ],
      "metadata": {
        "id": "D8JkT0jVViyU"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ftYfksDSncLg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Definir o SentimentDataset e os loaders de dados de treinamento e avaliação.\n",
        "\n",
        "**SentimentDataset**: organiza os dados de entrada (codificações e rótulos) para que possam ser usados pelo modelo.\n",
        "\n",
        "**DataLoader**: facilita o carregamento dos dados em lotes para alimentar o modelo durante o treinamento e a avaliação."
      ],
      "metadata": {
        "id": "Q6Oa8hOR1W9L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class SentimentAnalysisDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Usar .clone().detach() para evitar o aviso\n",
        "        item = {key: val[idx].clone().detach() for key, val in self.encodings.items()}\n",
        "\n",
        "        # Garantir que os rótulos estejam no formato correto\n",
        "        item['sentiment'] = torch.tensor(int(self.labels[idx]), dtype=torch.long)\n",
        "\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "# Mapear os rótulos para números usando o mapeamento\n",
        "label_mapping = {\"positivo\": 2, \"neutro\": 1, \"negativo\": 0}\n",
        "train_labels = [label_mapping[label] for label in train_df['sentiment']]\n",
        "eval_labels = [label_mapping[label] for label in eval_df['sentiment']]\n",
        "\n",
        "# Criar os datasets para treinamento e avaliação\n",
        "train_dataset = SentimentAnalysisDataset(train_encodings, train_labels)\n",
        "eval_dataset = SentimentAnalysisDataset(eval_encodings, eval_labels)\n"
      ],
      "metadata": {
        "id": "seVXyhnegaz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForSequenceClassification\n",
        "\n",
        "# Carregar o modelo BERT para classificação com 3 rótulos (positivo, neutro, negativo)\n",
        "model = BertForSequenceClassification.from_pretrained('neuralmind/bert-base-portuguese-cased', num_labels=3)\n"
      ],
      "metadata": {
        "id": "L2no0EGWIYhL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Definir o otimizador (usando Adam, mas pode ser alterado para outro otimizador)\n",
        "optimizer = optim.Adam(model.parameters(), lr=2e-5)  # lr = taxa de aprendizado (learning rate)\n",
        "\n",
        "# Definir a função de perda (loss function)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()  # Como você tem rótulos categóricos (positivo, neutro, negativo), CrossEntropyLoss é adequada\n"
      ],
      "metadata": {
        "id": "0bDkXMVRIRlX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "# Defina o número de épocas\n",
        "num_epochs = 5  # Defina o número de épocas que você deseja treinar\n",
        "\n",
        "# Inicialize listas para armazenar as métricas\n",
        "train_precisions = []\n",
        "val_precisions = []\n",
        "\n",
        "train_recalls = []\n",
        "val_recalls = []\n",
        "\n",
        "train_f1s = []\n",
        "val_f1s = []\n",
        "\n",
        "# Crie DataLoader para os datasets de treinamento e validação\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)  # Ajuste o tamanho do lote conforme necessário\n",
        "eval_loader = DataLoader(eval_dataset, batch_size=16)  # Ajuste o tamanho do lote conforme necessário\n",
        "\n",
        "# Loop de treinamento\n",
        "for epoch in range(num_epochs):\n",
        "    # Treinamento\n",
        "    model.train()\n",
        "    train_preds = []\n",
        "    train_labels = []\n",
        "\n",
        "    for batch in train_loader:\n",
        "        optimizer.zero_grad()  # Zera os gradientes\n",
        "        outputs = model(batch['input_ids'], attention_mask=batch['attention_mask'])\n",
        "        loss = loss_fn(outputs.logits, batch['sentiment'])\n",
        "        loss.backward()  # Calcula os gradientes\n",
        "        optimizer.step()  # Atualiza os pesos\n",
        "\n",
        "        # Obter predições\n",
        "        preds = torch.argmax(outputs.logits, dim=1).cpu().numpy()\n",
        "        train_preds.extend(preds)\n",
        "        train_labels.extend(batch['sentiment'].cpu().numpy())\n",
        "\n",
        "    # Calcular precisão, recall e f1-score no conjunto de treino\n",
        "    train_precision, train_recall, train_f1, _ = precision_recall_fscore_support(train_labels, train_preds, average='weighted')\n",
        "    train_precisions.append(train_precision)\n",
        "    train_recalls.append(train_recall)\n",
        "    train_f1s.append(train_f1)\n",
        "\n",
        "    # Avaliação\n",
        "    model.eval()\n",
        "    val_preds = []\n",
        "    val_labels = []\n",
        "\n",
        "    with torch.no_grad():  # Desativa o cálculo de gradientes\n",
        "        for batch in eval_loader:\n",
        "            outputs = model(batch['input_ids'], attention_mask=batch['attention_mask'])\n",
        "            preds = torch.argmax(outputs.logits, dim=1).cpu().numpy()\n",
        "            val_preds.extend(preds)\n",
        "            val_labels.extend(batch['sentiment'].cpu().numpy())\n",
        "\n",
        "    # Calcular precisão, recall e f1-score no conjunto de validação\n",
        "    val_precision, val_recall, val_f1, _ = precision_recall_fscore_support(val_labels, val_preds, average='weighted')\n",
        "    val_precisions.append(val_precision)\n",
        "    val_recalls.append(val_recall)\n",
        "    val_f1s.append(val_f1)\n",
        "\n",
        "# Plotar as métricas\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Plot precisão\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_precisions, label='Precisão de Treinamento')\n",
        "plt.plot(val_precisions, label='Precisão de Validação')\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Precisão')\n",
        "plt.legend()\n",
        "plt.title('Precisão ao Longo das Épocas')\n",
        "\n",
        "# Plot F1-score\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(train_f1s, label='F1-Score de Treinamento')\n",
        "plt.plot(val_f1s, label='F1-Score de Validação')\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('F1-Score')\n",
        "plt.legend()\n",
        "plt.title('F1-Score ao Longo das Épocas')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "INc7an-eJFql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exemplo simples para plotar a acurácia ao longo das épocas\n",
        "epochs = [1, 2, 3]  # Substitua pelos valores reais\n",
        "accuracy = [0.82, 0.85, 0.88]  # Substitua pelos valores reais\n",
        "\n",
        "# Configurações do gráfico\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.plot(epochs, accuracy, label='Acurácia de Validação', marker='o', color='b')\n",
        "plt.title('Evolução da Acurácia Durante o Treinamento')\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Acurácia')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "tNcWdcACHwD_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Salvar o modelo treinado\n",
        "model.save_pretrained('caminho_para_salvar_o_modelo')\n",
        "tokenizer.save_pretrained('caminho_para_salvar_o_tokenizer')\n"
      ],
      "metadata": {
        "id": "cGV6CPvwJF_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configuração do ambiente de treinamento, permitindo o controle sobre o processo de otimização, salvamento de modelos e avaliação, garantindo o monitoraramento do desempenho ao longo do tempo."
      ],
      "metadata": {
        "id": "VAdnyxPSTPUT"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cFTqU3S9HuEb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Cálculo da matriz de confusão\n",
        "y_true = y_true_val  # Rótulos verdadeiros de validação\n",
        "y_pred = y_pred_val  # Rótulos previstos\n",
        "\n",
        "conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
        "             xticklabels=['Negativo', 'Neutro', 'Positivo'],\n",
        "             yticklabels=['Negativo', 'Neutro', 'Positivo'])\n",
        "plt.ylabel('Rótulos Verdadeiros')\n",
        "plt.xlabel('Rótulos Previsto')\n",
        "plt.title('Matriz de Confusão')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "imVD8LsKIVuw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Avaliação\n",
        "model.eval()\n",
        "y_true_val = []\n",
        "y_pred_val = []\n",
        "\n",
        "with torch.no_grad():  # Desativa o cálculo de gradientes\n",
        "    for batch in eval_loader:\n",
        "        outputs = model(batch['input_ids'], attention_mask=batch['attention_mask'])\n",
        "        preds = torch.argmax(outputs.logits, dim=1).cpu().numpy()  # Predições do modelo\n",
        "        y_pred_val.extend(preds)  # Adiciona predições na lista\n",
        "        y_true_val.extend(batch['sentiment'].cpu().numpy())  # Adiciona rótulos verdadeiros na lista\n",
        "\n",
        "# Cálculo da matriz de confusão\n",
        "y_true = y_true_val  # Rótulos verdadeiros de validação\n",
        "y_pred = y_pred_val  # Rótulos previstos\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred, labels=[0, 1, 2])  # Matriz de confusão para as 3 classes\n",
        "\n",
        "# Exibe a matriz de confusão de forma visual\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Negativo', 'Neutro', 'Positivo'])\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.title('Matriz de Confusão - Validação')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Chxx8kv1V9Iw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Criar o Trainer\n",
        "\n",
        "configura e inicia o treinamento do modelo BERT para classificação de sentimentos usando a biblioteca transformers\n"
      ],
      "metadata": {
        "id": "daTW-BwKpw_Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# métricas de desempenho do modelo no conjunto de dados de **avaliação**"
      ],
      "metadata": {
        "id": "rPZn8AY-5eMQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "AVALIAÇÃO"
      ],
      "metadata": {
        "id": "nkyoFe5hkZ_j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(train_losses, label='Training Loss', color='blue')\n",
        "plt.plot(eval_losses, label='Validation Loss', color='orange')\n",
        "plt.title('Loss over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "cr7ycbcOk6Xc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gráfico de Barras para a Distribuição de Sentimentos"
      ],
      "metadata": {
        "id": "7ZizTaaLGZAB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Supondo que a coluna 'label' contém 0 (Negativo), 1 (Positivo), e 2 (Neutro)\n",
        "sentiment_counts = df_PREFEITO['sentiment'].value_counts()\n",
        "\n",
        "# Configurações do gráfico\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.barplot(x=sentiment_counts.index, y=sentiment_counts.values, palette='viridis')\n",
        "plt.title('Distribuição de Sentimentos')\n",
        "plt.xlabel('Sentimento')\n",
        "plt.ylabel('Quantidade de Textos')\n",
        "plt.xticks(ticks=[0, 1, 2], labels=['Negativo', 'Positivo', 'Neutro'])\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "KYlBE0XZGYXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gráfico de Linha para Evolução Temporal dos Sentimentos\n"
      ],
      "metadata": {
        "id": "cTpVetTVGeF2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nuvem de Palavras"
      ],
      "metadata": {
        "id": "1UXoK3eoGhct"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar a distribuição dos rótulos\n",
        "print(df_PREFEITO['sentiment'].value_counts())\n"
      ],
      "metadata": {
        "id": "V_GDflJkaqjF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar se há textos vazios ou nulos\n",
        "print(df_PREFEITO[df_PREFEITO['sentiment'] == 2]['cleaned_text'].isna().sum())  # Verifica textos nulos\n",
        "print(df_PREFEITO[df_PREFEITO['sentiment'] == 2]['cleaned_text'].str.strip().eq('').sum())  # Verifica textos vazios\n"
      ],
      "metadata": {
        "id": "5Qpzx785atKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Matriz de Confusão\n"
      ],
      "metadata": {
        "id": "vhnx3JbGGlOj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "# Suponha que y_true são os rótulos verdadeiros e y_pred as previsões do modelo\n",
        "conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# Configurações do gráfico\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Negativo', 'Positivo', 'Neutro'], yticklabels=['Negativo', 'Positivo', 'Neutro'])\n",
        "plt.title('Matriz de Confusão')\n",
        "plt.xlabel('Previsões')\n",
        "plt.ylabel('Valores Reais')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "_qMnVLFwGkgD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gráfico de Perda e Acurácia do Modelo"
      ],
      "metadata": {
        "id": "BMs_MXgeGq3f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exemplo simples de visualização da perda (loss) ao longo das épocas\n",
        "epochs = [1, 2, 3]  # Substituir pelos valores reais\n",
        "training_loss = [0.5, 0.25, 0.15]  # Substituir pelos valores reais\n",
        "validation_loss = [0.55, 0.30, 0.20]  # Substituir pelos valores reais\n",
        "\n",
        "# Configurações do gráfico\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.plot(epochs, training_loss, label='Perda de Treinamento', marker='o')\n",
        "plt.plot(epochs, validation_loss, label='Perda de Validação', marker='o')\n",
        "plt.title('Evolução da Perda Durante o Treinamento')\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Perda (Loss)')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "HaqZb52AGrQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. Gráfico de Dispersão 3D\n",
        "\n",
        "Se você tem mais variáveis numéricas no seu dataset, o heatmap de correlação pode ser útil para identificar relações entre elas."
      ],
      "metadata": {
        "id": "J_tStSJ6I9Cd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "# Supondo que você já tem embeddings (vetores) para cada texto\n",
        "# Redução de dimensionalidade para 3D usando PCA\n",
        "pca = PCA(n_components=3)\n",
        "reduced_embeddings = pca.fit_transform(text_embeddings)  # Substitua 'text_embeddings' pelos vetores reais\n",
        "\n",
        "# Configurações do gráfico\n",
        "fig = plt.figure(figsize=(10,8))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "scatter = ax.scatter(reduced_embeddings[:,0], reduced_embeddings[:,1], reduced_embeddings[:,2], c=df_concatenado['label'], cmap='viridis')\n",
        "\n",
        "# Adicionar legenda e rótulos\n",
        "legend = ax.legend(*scatter.legend_elements(), title=\"Sentimento\")\n",
        "ax.add_artist(legend)\n",
        "ax.set_title('Visualização 3D de Textos em Embeddings')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "6OqdJ_KBI2TQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Heatmap de Correlação Entre Variáveis\n",
        "Se você tem mais variáveis numéricas no seu dataset, o heatmap de correlação pode ser útil para identificar relações entre elas.\n",
        "\n"
      ],
      "metadata": {
        "id": "2Me6PgWEIbgC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Mapeamento de rótulos\n",
        "label_mapping = {\"positivo\": 2, \"neutro\": 1, \"negativo\": 0}\n",
        "df_PREFEITO['sentiment'] = df_PREFEITO['sentiment'].map(label_mapping)\n",
        "\n",
        "# Criar a coluna text_length\n",
        "df_PREFEITO['text_length'] = df_PREFEITO['cleaned_text'].str.len()\n",
        "\n",
        "# Calcular a correlação entre o comprimento do texto e o sentimento\n",
        "corr = df_PREFEITO[['text_length', 'sentiment']].corr()\n",
        "\n",
        "# Configurações do gráfico\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(corr, annot=True, cmap='coolwarm', fmt='.2f')\n",
        "plt.title('Mapa de Calor das Correlações Entre Variáveis')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "HKGwPPHYHEsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gráfico de ROC (Receiver Operating Characteristic)\n",
        "Esse gráfico é utilizado para avaliar o desempenho do modelo de classificação. Ele mostra a relação entre a taxa de verdadeiros positivos e a taxa de falsos positivos."
      ],
      "metadata": {
        "id": "lgygoBe4HQuL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Learning Curve (Curva de Aprendizado)\n",
        "A curva de aprendizado ajuda a entender se o modelo está se ajustando bem ou sofrendo de overfitting ou underfitting."
      ],
      "metadata": {
        "id": "9lRUM0bdHnsL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Supondo que 'cleaned_text' é a coluna que contém o texto\n",
        "df_PREFEITO['text_length'] = df_PREFEITO['cleaned_text'].str.len()\n",
        "\n",
        "# Calcular a correlação entre o comprimento do texto e o sentimento\n",
        "corr = df_PREFEITO[['text_length', 'sentiment']].corr()\n",
        "\n",
        "# Configurações do gráfico\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(corr, annot=True, cmap='coolwarm', fmt='.2f')\n",
        "plt.title('Mapa de Calor das Correlações Entre Variáveis')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "OpmBVQOiHm6b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gráfico de Acurácia por Época\n",
        "Visualize a acurácia de validação ao longo das épocas para entender a evolução do desempenho do modelo.\n",
        "\n"
      ],
      "metadata": {
        "id": "xBh9MFWDHtSB"
      }
    }
  ]
}